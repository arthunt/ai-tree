{
  "metadata": {
    "title": "AI Knowledge Tree | AI Teadmiste Puu",
    "description": "Comprehensive interactive framework for teaching and understanding AI concepts. Terviklik interaktiivne raamistik AI kontseptide √µpetamiseks ja m√µistmiseks."
  },
  "header": {
    "title": "AI Knowledge Tree",
    "description": "Master AI fundamentals in ~2 hours",
    "treeView": "Concept Map",
    "treeViewAriaLabel": "Go to concept map view",
    "classicView": "Learning Path",
    "classicViewAriaLabel": "Back to learning path view"
  },
  "hero": {
    "title": "AI Knowledge Tree",
    "subtitle": "Understand AI well enough to make informed decisions. Master the fundamentals in ~2 hours.",
    "forWhom": "For trainers, team leads, and curious professionals",
    "classicViewTitle": "Learning Path",
    "classicViewDescription": "Step-by-step progression through concepts",
    "currentPage": "You are here",
    "treeViewTitle": "Concept Map",
    "treeViewDescription": "Visual overview of all concepts",
    "clickHere": "Click here ‚Üí",
    "or": "or",
    "treeEmoji": "Tree emoji",
    "bookEmoji": "Book",
    "startFromRoots": "Start from roots and move up or scroll freely",
    "newToAI": "New to AI?",
    "beginnerPathDesc": "Start here! Understand the basics in ~30 minutes.",
    "startWithTokens": "Start with Tokens",
    "startLearning": "Start Learning",
    "hook": "You already use AI. Now understand how it works.",
    "showMore": "Show more",
    "showLess": "Show less"
  },
  "brand": {
    "heroOrigin": "From dendron (Greek: tree) + dendrites (your neurons that grow when you learn)",
    "footerTitle": "Why Dendrix?",
    "footerStory": "Dendrites are tree-shaped brain cells that sprout new branches every time you learn something. Dendrix (dendron + dendrites) maps AI knowledge the way your brain actually stores it ‚Äî from roots to leaves."
  },
  "levels": {
    "roots": "Roots",
    "trunk": "Trunk",
    "branches": "Branches",
    "leaves": "Leaves",
    "totalTime": "Complete path: ~2 hours",
    "levelTime": {
      "roots": "~25 min",
      "trunk": "~30 min",
      "branches": "~35 min",
      "leaves": "~30 min",
      "fruits": "~20 min",
      "orchard": "~15 min"
    }
  },
  "treeView": {
    "title": "AI Knowledge Tree - Concept Map",
    "description": "All concepts in one view",
    "instructionsTitle": "Interactive Concept Map",
    "instructionsText": "Hover over a concept to highlight it. Click to open detailed view.",
    "ariaLabel": "Concept map",
    "diagramAriaLabel": "AI concepts map diagram",
    "legendHeading": "Tree levels legend",
    "rootsEmoji": "Seedling emoji",
    "trunkEmoji": "Evergreen tree emoji",
    "branchesEmoji": "Green plant emoji",
    "leavesEmoji": "Leaves emoji",
    "rootsLabel": "1. Roots",
    "trunkLabel": "2. Trunk",
    "branchesLabel": "3. Branches",
    "leavesLabel": "4. Leaves",
    "fruitsLabel": "5. Fruits",
    "orchardLabel": "6. Orchard",
    "introducedLabel": "Introduced",
    "keyPaperLabel": "Key Paper",
    "masterSkillLabel": "Master This Skill",
    "viewProgramLabel": "View Program",
    "conceptDeepDive": "Concept Deep-Dive",
    "readMore": "Read more...",
    "exploreStage": "Explore {stage} stage ‚Üí"
  },
  "viewMode": {
    "both": "Both",
    "simple": "Simple",
    "technical": "Technical",
    "ariaLabel": "Content mode selection",
    "tooltip": {
      "simple": "Simple metaphors and everyday examples",
      "technical": "Technical explanations for developers",
      "both": "Show both side by side"
    }
  },
  "nameToggle": {
    "simple": "Simple names",
    "technical": "Technical names",
    "ariaLabel": "Name display selection"
  },
  "darkMode": {
    "toggle": "Dark mode",
    "ariaLabel": "Dark/light mode selection",
    "switchToDark": "Switch to dark mode",
    "switchToLight": "Switch to light mode"
  },
  "settings": {
    "ariaLabel": "Open settings menu",
    "viewMode": "View Mode",
    "theme": "Theme",
    "language": "Language"
  },
  "welcome": {
    "title": "Welcome to AI Knowledge Tree",
    "subtitle": "Your guide to understanding AI ‚Äî in ~2 hours",
    "close": "Close",
    "skip": "Skip",
    "back": "Back",
    "next": "Next",
    "getStarted": "Get Started!",
    "stepOf": "Step {current} of {total}",
    "step1Title": "The Tree Metaphor",
    "step1Desc": "AI concepts organized like a growing tree",
    "step1Item1": "Roots ‚Äî Foundations: Tokens, Vectors, Attention (start here!)",
    "step1Item2": "Trunk ‚Äî Engineering: Prompting, Temperature, Context",
    "step1Item3": "Branches ‚Äî Applications: RAG, Agents, Function Calling",
    "step1Item4": "Leaves ‚Äî Trends: Green AI, Reasoning Models, MoE",
    "step2Title": "Two Ways to Explore",
    "step2Desc": "Choose the view that works for you",
    "step2Item1": "Learning Path ‚Äî Step-by-step progression from roots to leaves",
    "step2Item2": "Concept Map ‚Äî Visual overview of all concepts at once",
    "step2Item3": "Search (Cmd+K) ‚Äî Jump directly to any concept",
    "step3Title": "Track Your Progress",
    "step3Desc": "Learn at your own pace",
    "step3Item1": "Each concept takes 3-8 minutes to read",
    "step3Item2": "Mark concepts as learned to track progress",
    "step3Item3": "Switch between Simple and Technical explanations anytime"
  },
  "footer": {
    "description": "AI Knowledge Tree ‚Äì Interactive learning tool for understanding AI concepts",
    "version": "Version",
    "reportIssue": "Report Issue"
  },
  "complexity": {
    "level": "Concept depth",
    "1": "Core Idea",
    "2": "Connected",
    "3": "Deep Dive",
    "tooltip1": "A single, focused concept ‚Äî one clear idea to grasp",
    "tooltip2": "Multiple ideas that link together ‚Äî understanding relationships between parts",
    "tooltip3": "Dense, multi-layered topic with many prerequisites and interconnections"
  },
  "loading": {
    "default": "Loading...",
    "concepts": "Loading concepts...",
    "tree": "Loading tree...",
    "content": "Loading content..."
  },
  "concept": {
    "simpleName": "Simple name",
    "metaphor": "Metaphor",
    "closeAriaLabel": "Close detailed view",
    "closeDialog": "Close dialog window",
    "viewDetails": "View details",
    "viewFullSize": "View full size",
    "beginnerPath": "Beginner Path",
    "readingTime": "min read",
    "learnFirst": "Learn first",
    "prerequisiteHelp": "Understanding these topics will help you better grasp this concept:",
    "navigateTo": "Navigate to topic",
    "simpleMetaphor": "Simple Metaphor",
    "technicalExplanation": "Technical Explanation",
    "codeExample": "Code Example",
    "pressEscToClose": "Press ESC or click outside to close",
    "backToTree": "Back to Tree",
    "share": "Share this concept",
    "shareNative": "Share",
    "shareTwitter": "Share on X (Twitter)",
    "shareLinkedIn": "Share on LinkedIn",
    "copyLink": "Copy link",
    "linkCopied": "Link copied!",
    "completed": "Completed",
    "markAsComplete": "Mark as understood",
    "markedComplete": "Understood!",
    "conceptMarkedComplete": "Concept marked as complete!",
    "undo": "Undo",
    "simpleMode": "Simple",
    "technicalMode": "Technical",
    "explanation": "Explanation",
    "visual": "Visual",
    "code": "Code",
    "whyThisCode": "Why this code?",
    "howToUse": "How to use",
    "tryItOut": "Try it out",
    "visualComingSoon": "Visual representation coming soon",
    "visualComingSoonDesc": "We're working on adding visual content for this concept.",
    "codeComingSoon": "Code example coming soon",
    "codeComingSoonDesc": "We're preparing a practical code example for this concept.",
    "swipeHint": "Swipe left/right for prev/next concept",
    "copyCode": "Copy code",
    "codeCopied": "Code copied!"
  },
  "tokenizer": {
    "title": "Tokenizer Demo",
    "subtitle": "See how AI sees text",
    "showInfo": "Show info",
    "hideInfo": "Hide info",
    "inputLabel": "Enter text to tokenize",
    "inputPlaceholder": "Write something to see how AI tokenizes text...",
    "tokensLabel": "Tokens:",
    "tokenCount": "{count} {count, plural, one {token} other {tokens}}",
    "tokensPlaceholder": "Tokens will appear here...",
    "infoTitle": "What are tokens?",
    "infoText": "Language models don't see text the way we do. They break text into smaller pieces called <em>tokens</em>. A token can be a word, part of a word, or even a single character. This demo shows a simplified version!",
    "estimatedCost": "Estimated cost (GPT-4)",
    "costTip": "<strong>Tip:</strong> Longer texts = more tokens = higher cost. Learn to optimize your prompts!",
    "tryExamples": "Try examples:",
    "example1": "Hello, world!",
    "example2": "GPT-4 costs 2024",
    "example3": "Artificial intelligence",
    "example4": "Machine learning is fascinating",
    "digitInsight": "<strong>Numbers split into digits!</strong> AI doesn't see \"2024\" as one number ‚Äî it becomes 4 separate tokens (2, 0, 2, 4). Each digit gets its own <em>vector</em> (numerical meaning). That's why AI can struggle with math ‚Äî it processes digits one by one, not as whole numbers.",
    "subwordInsight": "<strong>Long words get split!</strong> Tokens marked with <code>##</code> are subword pieces. AI breaks unfamiliar or long words into smaller known parts, similar to how you might sound out an unfamiliar word syllable by syllable.",
    "disclaimer": "This is a simplified tokenizer. Real language models use more sophisticated methods like BPE (Byte Pair Encoding) or WordPiece."
  },
  "sprout": {
    "phaseLabel": "Phase 2: Foundations",
    "title": "The Sprout",
    "subtitle": "Before the tree can grow branches, it needs strong roots. Understand the 6 core mechanisms that power every AI model.",
    "card": {
      "analogyLabel": "Analogy",
      "readFull": "Read full lesson",
      "tapToLearn": "Tap to learn",
      "visualLink": "Tap to interact"
    },
    "inputPlaceholder": "Ask about these concepts..."
  },
  "navigation": {
    "viewOptions": "View options",
    "levelSections": "AI concept levels",
    "treeLevels": "Tree level navigation",
    "openNavPanel": "Open navigation panel",
    "closeNavPanel": "Close navigation panel",
    "goToLevel": "Go to {level} level",
    "currentLevel": "Current",
    "conceptsCompleted": "concepts understood",
    "backToTop": "Back to top",
    "switchToEstonian": "Switch to Estonian",
    "switchToEnglish": "Switch to English",
    "levels": {
      "roots": "Roots",
      "trunk": "Trunk",
      "branches": "Branches",
      "leaves": "Leaves",
      "fruits": "Fruits",
      "sapling": "Sapling",
      "orchard": "Orchard"
    }
  },
  "journey": {
    "title": "Your Learning Path",
    "subtitle": "From everyday AI to deep understanding ‚Äî like growing a tree from roots to leaves.",
    "roots": "Foundation",
    "rootsDesc": "Tokens, vectors & the building blocks",
    "trunk": "Core Mechanics",
    "trunkDesc": "How models learn and generate",
    "branches": "Applications",
    "branchesDesc": "RAG, agents & real-world tools",
    "leaves": "Mastery",
    "leavesDesc": "Fine-tuning, safety & beyond"
  },
  "levelSection": {
    "conceptCount": "{count} concepts",
    "concepts": "{level} concepts"
  },
  "organicTree": {
    "clickForDetails": "Click for details",
    "simple": "Core Idea",
    "intermediate": "Connected",
    "advanced": "Deep Dive"
  },
  "search": {
    "button": "Search",
    "buttonLabel": "Open search (Cmd+K)",
    "placeholder": "Search concepts...",
    "inputLabel": "Search for AI concepts",
    "instructions": "Use arrow keys to navigate, Enter to select, and Escape to close",
    "close": "Close search",
    "noResults": "No concepts found",
    "tryDifferent": "Try a different search term",
    "recentSearches": "Recent Searches",
    "clearRecent": "Clear",
    "popularConcepts": "Popular Concepts",
    "navigate": "Navigate",
    "select": "Select",
    "resultsCount": "{count} {count, plural, one {result} other {results}}",
    "level": {
      "roots": "Roots",
      "trunk": "Trunk",
      "branches": "Branches",
      "leaves": "Leaves",
      "fruits": "Fruits",
      "orchard": "Orchard"
    }
  },
  "skillSelector": {
    "title": "Where should we start?",
    "subtitle": "Choose your experience level",
    "close": "Close modal",
    "beginner": {
      "title": "New to AI",
      "description": "Start from the basics. Learn what tokens, vectors, and transformers are.",
      "time": "~30 min to get started"
    },
    "intermediate": {
      "title": "Exploring AI",
      "description": "Know the basics? Dive into how models learn and generate content.",
      "time": "~45 min deeper dive"
    },
    "advanced": {
      "title": "Building with AI",
      "description": "Ready for advanced topics like fine-tuning, RAG, and agents.",
      "time": "~35 min advanced topics"
    },
    "skipAndExplore": "Skip and explore freely"
  },
  "vectorDemo": {
    "title": "Vector Similarity Demo",
    "subtitle": "Explore how AI understands word meanings",
    "showInfo": "Show info",
    "hideInfo": "Hide info",
    "reset": "Reset",
    "word": "Word",
    "optional": "(optional)",
    "wordPlaceholder": "e.g. cat, happy, king",
    "calculate": "Calculate Similarity",
    "similarityScores": "Similarity Scores:",
    "similarityHigh": "Very similar",
    "similarityMedium": "Somewhat similar",
    "similarityLow": "Not similar",
    "visualization": "2D Visualization:",
    "visualizationAriaLabel": "2D visualization of word similarities in vector space",
    "visualizationHint": "Words closer together are more similar in meaning. Hover over points for details.",
    "infoTitle": "What are embeddings?",
    "infoText": "AI represents words as vectors (lists of numbers) called <em>embeddings</em>. Similar words have similar vectors. This demo uses simplified 10-dimensional vectors, but real models like GPT use 1,536+ dimensions! The 2D plot shows these high-dimensional relationships projected into a space we can see.",
    "tryExamples": "Try examples:",
    "exampleLabel1": "king, queen, prince",
    "exampleWords1": "king, queen, prince",
    "exampleLabel2": "cat, dog, car",
    "exampleWords2": "cat, dog, car",
    "exampleLabel3": "happy, sad, angry",
    "exampleWords3": "happy, sad, angry",
    "exampleLabel4": "apple, banana, pizza",
    "exampleWords4": "apple, banana, pizza",
    "exampleLabel5": "computer, phone, tree",
    "exampleWords5": "computer, phone, tree",
    "disclaimer": "This demo uses pre-computed simplified embeddings. Real AI models create embeddings dynamically based on context and use thousands of dimensions for more nuanced understanding."
  },
  "codeBlock": {
    "copied": "Copied!",
    "copiedAriaLabel": "Copied!",
    "copy": "Copy",
    "copyAriaLabel": "Copy code",
    "explanation": "üí° Explanation: "
  },
  "quickJump": {
    "ariaLabel": "Scroll down and start learning",
    "startLearning": "Start learning"
  },
  "skeleton": {
    "loadingTree": "Loading tree..."
  },
  "toast": {
    "closeAriaLabel": "Close notification"
  },
  "visuals": {
    "attention": {
      "title": "Attention Mechanism ‚Äî Focus",
      "inputSentence": "Input sentence:",
      "word": {
        "went": "went",
        "store": "to store",
        "and": "and",
        "she": "she",
        "bought": "bought",
        "milk": "milk"
      },
      "processing": "When processing \"she\" (it/she/he):",
      "strong": "Strong (95%) ‚Äî refers to Mari",
      "medium": "Medium (72%)",
      "explanationTitle": "Attention shows which words are important for understanding each word",
      "explanationLine1": "\"she\" pays strong attention to \"Mari\" to know who is being referred to.",
      "explanationLine2": "Arrow thickness = attention strength. This helps the model understand relationships."
    },
    "prefillDecode": {
      "title": "Prefill vs Decode ‚Äî Reading vs Writing",
      "prefillTitle": "PREFILL ‚Äî Reading",
      "decodeTitle": "DECODE ‚Äî Writing",
      "token": {
        "write": "Write",
        "me": "me",
        "a": "a",
        "story": "story",
        "once": "Once",
        "upon": "upon"
      },
      "allAtOnce": "All processed at once",
      "fastParallel": "‚ö° Fast & Parallel",
      "prefillSpeed": "~50ms for 100 tokens",
      "oneAtATime": "One token at a time",
      "sequential": "üê¢ Sequential",
      "decodeSpeed": "~50ms per token",
      "decodeExample": "(100 tokens = 5 seconds)",
      "whyMatters": "Why This Matters",
      "explanationLine1": "Prefill processes your entire prompt instantly (parallel). Decode generates each new word one-by-one (sequential).",
      "explanationLine2": "This is why long responses take time, even though reading your question is instant."
    },
    "contextWindow": {
      "title": "Context Window ‚Äî Working Memory",
      "tokenFlow": "Token Flow:",
      "forgotten": "Forgotten",
      "pastLimit": "Past limit",
      "activeContext": "ACTIVE CONTEXT",
      "modelCanSee": "Model can \"see\" and use this",
      "available": "Available",
      "spaceLeft": "Space left",
      "flowDirection": "Tokens flow through window ‚Üí",
      "sizesByModel": "Context Window Sizes by Model",
      "gpt35Size": "4K tokens",
      "gpt4Size": "8K tokens",
      "gpt4TurboSize": "128K tokens",
      "claudeSize": "200K tokens",
      "visualScale": "Visual scale (1K = 1px width):",
      "explanation": "Think of it like RAM: larger context = can remember more of your conversation, but costs more and runs slower."
    },
    "hallucinations": {
      "title": "Hallucinations ‚Äî Confident Fabrications",
      "subtitle": "Both responses look equally confident, but one is completely wrong!",
      "hallucination": "‚ùå HALLUCINATION",
      "correct": "‚úì CORRECT",
      "question": "Q: Who built the Eiffel Tower?",
      "answerStart": "A: The Eiffel Tower was built in",
      "wrongFact": "1887 by Claude Monet",
      "correctFact": "1889 by Gustave Eiffel",
      "answerEnd": "as part of the World's Fair in Paris.",
      "confidence94": "Confidence: 94%",
      "confidence96": "Confidence: 96%",
      "problem": "‚ö†Ô∏è The Problem: Same confidence level!",
      "whyTitle": "Why Hallucinations Happen",
      "reason1": "‚Ä¢ LLMs generate text based on patterns, not facts from a database",
      "reason2": "‚Ä¢ They don't know when they're making things up ‚Äî they just predict likely next words",
      "reason3": "‚Ä¢ High confidence ‚â† accurate. The model can be very confident about wrong information",
      "tip": "‚úì Always verify important facts, especially dates, names, and technical details!"
    },
    "trainingInference": {
      "title": "Training vs Inference ‚Äî School vs Work",
      "trainingTitle": "TRAINING",
      "trainingPhase": "(Learning Phase)",
      "inferenceTitle": "INFERENCE",
      "inferencePhase": "(Using Phase)",
      "time": "Time",
      "cost": "Cost",
      "data": "Data",
      "modelWeights": "Model Weights",
      "trainingTime": "Weeks to Months",
      "trainingCost": "$2M - $100M+",
      "trainingGpus": "1,000s - 10,000s",
      "trainingData": "Terabytes",
      "weightsChanging": "CHANGING ‚ö°",
      "trainingDesc": "Learns patterns from billions of examples",
      "inferenceTime": "Milliseconds",
      "inferenceCost": "$0.002 per query",
      "inferenceGpus": "1 - 8",
      "inferenceData": "Your prompt",
      "weightsFrozen": "FROZEN üîí",
      "inferenceDesc": "Uses learned patterns to answer your questions",
      "explanation": "Training happens once (expensive). Inference happens millions of times per day (cheap & fast)."
    },
    "transformers": {
      "title": "Transformers ‚Äî Master Architecture",
      "subtitle": "The architecture behind GPT, Claude, Llama, and most modern AI models",
      "inputText": "INPUT TEXT",
      "tokenEmbedding": "Token Embedding",
      "blocksLabel": "TRANSFORMER BLOCKS √ó N (e.g., 12-96 layers)",
      "multiHeadAttention": "Multi-Head Attention üîç",
      "feedForward": "Feed-Forward + Layer Norm",
      "repeatedN": "(repeated N times)",
      "outputProbs": "Output Probabilities",
      "nextToken": "NEXT TOKEN",
      "annotationAttention1": "‚Üê Where words look",
      "annotationAttention2": "at each other",
      "annotationFF1": "‚Üê Processing &",
      "annotationFF2": "transformation",
      "annotationOutput1": "‚Üê Predicts next word",
      "annotationOutput2": "probabilities",
      "keyInnovation": "Key Innovation",
      "innovation1": "‚Ä¢ Parallel processing",
      "innovation2": "‚Ä¢ Attention mechanism",
      "innovation3": "‚Ä¢ Scales to billions of",
      "innovation3b": "parameters"
    },
    "temperature": {
      "title": "Temperature: Creativity Knob",
      "lowLabel": "Low (0.0 - 0.3)",
      "lowDesc": "‚ùÑÔ∏è Predictable",
      "medLabel": "Medium (0.7)",
      "medDesc": "üéØ Balanced",
      "highLabel": "High (1.5 - 2.0)",
      "highDesc": "üî• Chaotic",
      "probDistribution": "Probability Distribution",
      "exampleOutput": "Example Output",
      "lowExample1": "\"The cat sat on the",
      "lowExample2": "mat. The cat sat on",
      "lowExample3": "the mat. The cat...\"",
      "lowNote": "(repetitive, safe)",
      "medExample1": "\"The cat rested on",
      "medExample2": "the warm mat,",
      "medExample3": "watching birds...\"",
      "medNote": "(natural, coherent)",
      "highExample1": "\"Quantum bicycle",
      "highExample2": "dreams! Purple",
      "highExample3": "elephant Tuesday...\"",
      "highNote": "(random, incoherent)"
    },
    "promptingBasics": {
      "title": "Asking Good Questions",
      "badPrompt": "‚ùå Bad Prompt",
      "badExample": "\"Tell me about food\"",
      "badResult1": "\"Food is a substance that...\"",
      "badResult2": "[vague essay about food]",
      "badResult3": "\"...provides nutrition...\"",
      "goodPrompt": "‚úÖ Good Prompt",
      "goodExample1": "\"List 3 vegetarian recipes",
      "goodExample2": "under 30 min with 20g+ protein\"",
      "goodResult1": "1. Chickpea curry (25 min, 22g)",
      "goodResult2": "2. Tofu stir-fry (20 min, 24g)",
      "goodResult3": "3. Lentil dal (28 min, 21g)",
      "principlesTitle": "5 Prompting Principles",
      "principle1": "Be specific",
      "principle1Desc": "State exactly what you want",
      "principle2": "Give context",
      "principle2Desc": "Provide relevant background",
      "principle3": "Set format",
      "principle3Desc": "Specify output structure",
      "principle4": "Use examples",
      "principle4Desc": "Show what you mean",
      "principle5": "Break complex tasks",
      "principle5Desc": "Split into smaller steps"
    },
    "contextEngineering": {
      "title": "Context Engineering ‚Äî Prompt Anatomy",
      "systemRole": "System Role",
      "systemRoleExample": "\"You are a helpful coding assistant...\"",
      "rules": "Rules & Constraints",
      "rulesExample": "\"Only use Python. Max 50 lines. No external libs.\"",
      "format": "Output Format",
      "formatExample": "\"Return JSON with keys: answer, confidence, source\"",
      "examples": "Examples (Few-Shot)",
      "examplesExample": "\"Input: 'hello' ‚Üí Output: {greeting: true}\"",
      "userQuery": "User Query",
      "conclusion": "Better context = Better AI output"
    },
    "ragPipeline": {
      "title": "RAG Pipeline ‚Äî Retrieval-Augmented Generation",
      "query": "Query",
      "queryExample": "\"What is...?\"",
      "retrieve": "RETRIEVE",
      "retrieveStep1": "1. Embed query",
      "retrieveStep2": "2. Vector search",
      "retrieveStep3": "3. Top-K results",
      "documentDb": "Document DB",
      "documentDbDesc": "Vectors + metadata",
      "augment": "AUGMENT",
      "augmentDesc1": "Combine query +",
      "augmentDesc2": "retrieved context",
      "generate": "GENERATE",
      "generateDesc1": "LLM produces",
      "generateDesc2": "grounded answer",
      "answer": "Answer",
      "answerLine1": "Grounded response with",
      "answerLine2": "sources cited from",
      "answerLine3": "retrieved documents"
    },
    "memoryTypes": {
      "title": "AI Memory Types",
      "shortTerm": "Short-Term Memory",
      "shortTermDesc": "(Context Window)",
      "message5": "üë§ Latest user message",
      "message4": "ü§ñ AI response",
      "message3": "üë§ Earlier message (fading...)",
      "shortTermProp1": "‚è±Ô∏è Limited to session",
      "shortTermProp2": "üìè Fixed token limit",
      "longTerm": "Long-Term Memory",
      "longTermDesc": "(External Storage)",
      "facts": "User facts",
      "preferences": "Preferences",
      "history": "Conversation history",
      "patterns": "Learned patterns",
      "longTermProp1": "üíæ Persists across sessions",
      "longTermProp2": "üîç Searchable via vectors",
      "store": "Store ‚Üí",
      "retrieveAction": "‚Üê Retrieve"
    },
    "lora": {
      "title": "LoRA ‚Äî Low-Rank Adaptation",
      "baseModel": "Base Model",
      "frozen": "üîí Frozen",
      "loraAdapters": "LoRA Adapters",
      "trained": "üî• Trained",
      "layer": "Layer",
      "frozenWeights": "Frozen weights",
      "whyLora": "Why LoRA?",
      "benefit1": "‚úì Train 0.1% of parameters",
      "benefit2": "‚úì 100x cheaper than full",
      "benefit3": "‚úì Swap adapters easily",
      "benefit4": "‚úì Keep base model intact",
      "input": "Input ‚Üì",
      "output": "Output ‚Üì"
    },
    "security": {
      "title": "AI Security ‚Äî Attack Surfaces",
      "inputZone": "INPUT ZONE",
      "modelZone": "MODEL ZONE",
      "outputZone": "OUTPUT ZONE",
      "threat": "‚ö†Ô∏è Threat",
      "defense": "üõ°Ô∏è Defense",
      "inputThreat": "Prompt injection attacks",
      "inputDefense": "Input validation & filtering",
      "modelThreat": "Training data poisoning",
      "modelDefense": "Alignment & RLHF",
      "outputThreat": "Harmful content generation",
      "outputDefense": "Output filtering & guardrails",
      "summaryTitle": "Defense in Depth: Protect at every layer",
      "summaryDesc": "No single defense is enough ‚Äî combine input, model, and output protections"
    },
    "agentLoop": {
      "title": "AI Agent Loop",
      "observe": "OBSERVE",
      "think": "THINK",
      "act": "ACT",
      "toolSearch": "Search",
      "toolCode": "Code",
      "toolDatabase": "Database",
      "consultant": "Consultant",
      "consultantDesc": "Gives advice",
      "agent": "Agent",
      "agentDesc": "Takes action"
    },
    "mcpArchitecture": {
      "title": "MCP Architecture",
      "beforeMcp": "Before MCP",
      "customIntegration": "Custom integration",
      "forEachTool": "for each tool",
      "afterMcp": "After MCP",
      "mcpServer": "MCP Server",
      "analogy": "Like a universal adapter for AI tools"
    },
    "complexityLevels": {
      "title": "AI Complexity Levels",
      "llmChat": "LLM / Chat",
      "llmDesc": "Answers questions",
      "reasoningModel": "Reasoning Model",
      "reasoningDesc": "Thinks step by step",
      "agentDoer": "Agent",
      "agentDesc": "Takes action",
      "kitchenAnalogy": "Kitchen Analogy",
      "recipeBook": "Recipe Book",
      "providesInfo": "Provides info",
      "headChef": "Head Chef",
      "reasoning": "Reasoning",
      "plansMenu": "Plans the menu",
      "cook": "Cook",
      "agentLabel": "Agent",
      "makesFood": "Makes the food"
    },
    "agiAsi": {
      "title": "AI Capability Spectrum",
      "narrowAi": "Narrow AI",
      "today": "(Today)",
      "agi": "AGI",
      "future": "(Future?)",
      "agiDesc1": "Good at ALL",
      "agiDesc2": "human tasks",
      "asi": "ASI",
      "hypothetical": "(Hypothetical)",
      "asiDesc1": "Surpasses ALL",
      "asiDesc2": "human capability",
      "weAreHere": "We are here"
    },
    "functionCalling": {
      "title": "Function Calling: Giving AI Hands",
      "user": "USER",
      "aiModel": "AI MODEL",
      "function": "FUNCTION",
      "questionExample": "\"What's the weather?\"",
      "answerExample": "\"It's 5¬∞C and rainy\"",
      "aiGenerates": "AI generates the call",
      "appExecutes": "Your app executes it"
    },
    "greenAi": {
      "title": "Green AI: Energy Efficiency",
      "trainingCost": "Training Cost",
      "co2Emissions": "CO‚ÇÇ Emissions",
      "inferenceCost": "Inference Cost (per query)",
      "reduction": "90% reduction",
      "conclusion": "Same quality, fraction of the cost"
    },
    "moe": {
      "inputQuery": "Input Query",
      "router": "Router",
      "expert": "Expert",
      "combinedOutput": "Combined Output",
      "activeExperts": "Active: 2/8 experts",
      "fasterCheaper": "Faster + Cheaper"
    },
    "reasoningModels": {
      "title": "Regular LLM vs Reasoning Model",
      "regularLlm": "Regular LLM",
      "answer": "Answer: 425",
      "sometimesWrong": "(sometimes wrong)",
      "fast": "‚ö° Fast (instant)",
      "cheap": "üí∞ Cheap",
      "noVerification": "‚ö†Ô∏è No verification",
      "reasoningModel": "Reasoning Model",
      "verifiedAnswer": "Answer: 425 ‚úì",
      "slower": "üê¢ Slower (multi-step)",
      "verified": "‚úÖ Verified & accurate",
      "bestFor": "Best for: Math, Code, Logic & Complex Reasoning"
    }
  },
  "conceptData": {
    "moe": {
      "title": "Mixture of Experts (MoE)",
      "simpleName": "Council of Experts",
      "explanation": "MoE models activate only a few specialized 'experts' for each query instead of using the full model. Like a large company where different departments handle different tasks ‚Äî you don't need accounting to answer marketing questions. This makes the model faster and cheaper while maintaining quality.",
      "metaphor": "Imagine going to a large hospital with different specialists. The receptionist (router) reads your symptoms and sends you only to the relevant doctors ‚Äî not to all 100 specialists. If you have a skin issue, you see the dermatologist. If it's a broken bone, you see the orthopedist. The hospital is huge, but you only use 2-3 specialists per visit. That's exactly how MoE works: 8 expert sub-models, but only 2 activate per query."
    },
    "agi-asi": {
      "title": "AGI and ASI",
      "simpleName": "Superintelligence",
      "explanation": "AGI (Artificial General Intelligence) would be AI that matches human capability across all cognitive tasks ‚Äî learning, reasoning, creativity, common sense. ASI (Artificial Superintelligence) would surpass human intelligence in every domain. Today's AI is 'narrow' ‚Äî excellent at specific tasks but lacking general understanding. The path from narrow AI to AGI to ASI is uncertain, with estimates ranging from decades to never.",
      "metaphor": "Think of it as an educational journey: Today's AI is like a brilliant student who aces one exam but fails others (Narrow AI). AGI would be like Einstein ‚Äî world-class at everything from physics to music to conversation. ASI would be an intelligence so far beyond Einstein that we can't even comprehend what it would understand ‚Äî like trying to explain quantum physics to a goldfish."
    },
    "green-ai": {
      "title": "Green AI (Sustainability)",
      "simpleName": "Green AI",
      "explanation": "Training large AI models consumes enormous energy ‚Äî GPT-3 training emitted as much CO‚ÇÇ as 5 cars over their lifetime. Green AI focuses on making models more efficient: smaller models with similar performance, optimized training methods, better hardware utilization, and running inference efficiently. Techniques like model distillation, quantization, and efficient architectures reduce both cost and environmental impact.",
      "metaphor": "It's like the shift from gas-guzzling SUVs to electric cars. Early AI models were powerful but wasteful ‚Äî like a Hummer getting 10 mpg. Green AI is about getting the same performance from a Tesla ‚Äî optimized, efficient, and sustainable. You still get where you need to go, but with 90% less energy consumption."
    },
    "reasoning-models": {
      "title": "Specialized Reasoning Models",
      "simpleName": "The Thinker",
      "explanation": "Reasoning models (like OpenAI's o1 or o3) don't just predict the next word ‚Äî they 'think' through problems step-by-step before answering. They use chain-of-thought reasoning internally, checking their work and exploring different approaches. This makes them much better at complex tasks like mathematics, coding, and logic puzzles, though they're slower and more expensive than standard models.",
      "metaphor": "It's the difference between speed chess and tournament chess. A regular LLM is like a speed chess player ‚Äî fast, intuitive, often brilliant, but sometimes makes mistakes under time pressure. A reasoning model is like a grandmaster taking 30 minutes per move, considering multiple strategies, anticipating consequences, and double-checking before committing. The reasoning model is slower, but it rarely makes logical errors."
    },
    "ai-agents": {
      "title": "AI Agents",
      "simpleName": "The Doer",
      "explanation": "AI Agents are autonomous systems that can use tools, make decisions, and execute multi-step tasks with minimal human intervention. Unlike a chatbot that just responds, an agent can: read your emails, search the web, write code, run it, debug errors, and complete the task. They operate in a loop: observe ‚Üí reason ‚Üí act ‚Üí observe results ‚Üí continue. Agents use function calling and tool integration to interact with the real world.",
      "metaphor": "The difference between a consultant and a worker. A regular chatbot is a consultant: you ask a question, get advice, but YOU do the work. An AI agent is a worker you hire: you say 'organize my travel to New York next week,' and it books flights, finds hotels, adds calendar events, and sends you a summary. You supervise, but the agent handles execution."
    },
    "mcp": {
      "title": "MCP (Model Context Protocol)",
      "simpleName": "The Connector",
      "explanation": "MCP is an open standard that lets AI models securely connect to external data sources and tools ‚Äî databases, APIs, file systems, business software ‚Äî through a unified interface. Instead of each AI tool building custom integrations, MCP provides one protocol that works everywhere. It's like USB for AI: plug in once, work with any compatible model or tool.",
      "metaphor": "Remember when every phone had a different charging cable ‚Äî Nokia, iPhone, Samsung all needed different connectors? Then USB-C came along and solved everything. MCP is the same idea for AI. Before MCP, connecting Claude to your database required custom code; connecting GPT required different code. With MCP, you write one connector and any MCP-compatible AI can use it. One cable, all devices."
    },
    "complexity-levels": {
      "title": "3 Complexity Levels",
      "simpleName": "Three Levels",
      "explanation": "AI systems operate at three levels of sophistication: (1) LLM Level ‚Äî pure text prediction, fast, stateless; (2) Reasoning Level ‚Äî chain-of-thought, multi-step problem solving, slower but more accurate; (3) Agent Level ‚Äî autonomous task execution with tools, memory, and decision loops. Each level builds on the previous one, adding capability and complexity. You choose the level based on your task: simple questions ‚Üí LLM, complex reasoning ‚Üí Reasoning model, autonomous work ‚Üí Agent.",
      "metaphor": "Think of a kitchen: (1) Cookbook (LLM) ‚Äî you give it a recipe request, it spits out instructions. Fast, no thinking. (2) Chef (Reasoning) ‚Äî you ask for a meal, the chef plans the menu, considers ingredient availability, timing, and presentation. Takes longer but higher quality. (3) Personal Cook (Agent) ‚Äî you say 'I'm hungry,' and they check your fridge, order missing ingredients, cook the meal, plate it, and clean up. Full autonomy."
    },
    "function-calling": {
      "title": "Function Calling",
      "simpleName": "Giving AI Hands",
      "explanation": "Function calling lets LLMs call external functions to retrieve data or perform actions they can't do on their own. The model decides when to call a function, generates the parameters, your code executes it, and the model uses the result to continue the conversation. For example, 'What's the weather?' ‚Üí model calls get_weather(location='New York') ‚Üí your code fetches real data ‚Üí model formats the response. This turns LLMs from pure chatbots into systems that can interact with the real world.",
      "metaphor": "Imagine hiring a brilliant intern who knows everything but has no hands. They can analyze, write, plan ‚Äî but can't open doors, press buttons, or fetch files. Function calling is like giving them a phone to call specialists: 'Call the weather service for the forecast,' 'Call the database team for customer data,' 'Call the email API to send this message.' The intern (LLM) orchestrates; the specialists (functions) do the physical work."
    },
    "context-engineering": {
      "title": "Context Engineering",
      "simpleName": "Stage Direction",
      "explanation": "Context engineering means carefully constructing the full environment in which the AI operates ‚Äî not just the question, but the role, rules, format expectations, examples, and constraints. A well-engineered context includes: system role ('you are an expert Python developer'), constraints ('max 50 lines, no external libraries'), format ('return JSON'), and examples (few-shot learning). This dramatically improves response quality, consistency, and safety.",
      "metaphor": "Think of it like directing a theater actor. You don't just hand them a script and hope for the best. You set the stage (environment), define their character (role), explain the tone (constraints), show them examples of similar performances (few-shot), and specify the desired outcome (format). A vague prompt is like saying 'act.' A well-engineered context is a full director's brief that guides the performance exactly where you want it."
    },
    "rag": {
      "title": "RAG (Retrieval-Augmented Generation)",
      "simpleName": "The Library",
      "explanation": "RAG combines information retrieval with text generation. Instead of relying only on the model's training data (which can be outdated or incomplete), RAG first searches a database for relevant documents, then feeds them into the prompt as context. The flow: (1) User asks a question ‚Üí (2) System searches vector database for relevant docs ‚Üí (3) Top results are added to the prompt ‚Üí (4) LLM generates answer based on retrieved context. This grounds responses in your specific data and reduces hallucinations.",
      "metaphor": "It's like an open-book exam vs. a closed-book exam. Without RAG, the AI relies purely on memory ‚Äî what it learned during training. With RAG, the AI can quickly search through a library (your database), find relevant pages, and cite them while answering. You ask 'What's our refund policy?' ‚Üí RAG finds the official policy document ‚Üí AI quotes it directly. Always up-to-date, always grounded in real data."
    },
    "memory": {
      "title": "Memory and State Management",
      "simpleName": "Memory",
      "explanation": "AI memory comes in two forms: (1) Short-term ‚Äî the conversation context window (last N tokens the model can 'see'), temporary, limited by model capacity; (2) Long-term ‚Äî external storage (databases, vector stores) that persists across sessions. Short-term memory is like working memory; long-term is like keeping notes. Advanced systems combine both: storing facts, preferences, and conversation history in a database, then retrieving relevant pieces when needed.",
      "metaphor": "Think of short-term memory as your notebook during a meeting ‚Äî you can see the last few pages, but older notes scroll off. Long-term memory is your filing cabinet ‚Äî everything is saved permanently, and you can search for it later. A smart assistant might remember 'user prefers dark roast coffee' in long-term storage, then retrieve it weeks later when you ask about coffee recommendations."
    },
    "lora": {
      "title": "LoRA & Fine-Tuning",
      "simpleName": "Continuing Education",
      "explanation": "LoRA (Low-Rank Adaptation) is a technique for fine-tuning large models efficiently. Instead of retraining all billions of parameters (expensive, slow), LoRA freezes the base model and trains small 'adapter' layers ‚Äî just 0.1% of the parameters. This makes fine-tuning 100x cheaper and faster while achieving similar results. You can swap adapters easily: one for medical text, one for legal, one for code. The base model stays unchanged.",
      "metaphor": "Imagine you have a brilliant university graduate (base model) who knows general knowledge. Instead of sending them back to university for 4 years (full fine-tuning) to specialize in law, you give them a short 3-month course (LoRA adapter). They keep all their general knowledge but gain specialized legal expertise. Later, you can swap the legal course for a medical course, and they adapt instantly. Same graduate, different specializations, minimal retraining."
    },
    "security": {
      "title": "AI Security",
      "simpleName": "Security",
      "explanation": "AI security involves protecting against three main attack surfaces: (1) Input attacks ‚Äî prompt injection, jailbreaking attempts to bypass rules; (2) Model attacks ‚Äî training data poisoning, extracting private information the model memorized; (3) Output attacks ‚Äî generating harmful content, leaking sensitive data. Defenses include input validation, output filtering, alignment training (RLHF), and defense-in-depth strategies that protect at every layer.",
      "metaphor": "Think of AI security like a nightclub bouncer working at three checkpoints: (1) The entrance (input) ‚Äî checking IDs, rejecting troublemakers trying to sneak in with fake prompts; (2) The interior (model) ‚Äî trained staff ensuring guests behave, no one's spiking drinks (poisoning training data); (3) The exit (output) ‚Äî making sure no one leaves with stolen property or dangerous items (harmful outputs). You need protection at all three points, not just one."
    },
    "temperature-sampling": {
      "title": "Temperature & Sampling",
      "simpleName": "Creativity Knob",
      "explanation": "Temperature controls the randomness of AI outputs by adjusting the probability distribution over next-token predictions. Low temperature (0.0-0.3) makes the model deterministic and conservative ‚Äî always picking the most likely word. High temperature (1.0-2.0) flattens the distribution, making unlikely words more probable, increasing creativity but risking incoherence. For factual tasks, use low temperature. For creative writing or brainstorming, use higher values. Sampling strategies like top-k and top-p further refine this control.",
      "metaphor": "Temperature is like the dial on a creativity machine. At 0 (freezing cold), the machine is a calculator ‚Äî always gives the same answer, predictable, safe. At 0.7 (room temperature), it's balanced ‚Äî natural, varied, but still coherent. At 2.0 (boiling hot), it's a wild artist throwing paint randomly ‚Äî creative chaos, often nonsensical. For 'What is 2+2?' use cold (0). For 'Write a surrealist poem,' use hot (1.5)."
    },
    "prompting-basics": {
      "title": "Prompting Basics",
      "simpleName": "Asking Good Questions",
      "explanation": "Effective prompting follows key principles: (1) Be specific ‚Äî vague requests get vague answers; (2) Provide context ‚Äî background info helps the model understand your needs; (3) Specify format ‚Äî tell the model how to structure the output (bullet points, JSON, table); (4) Use examples ‚Äî show the model what you want (few-shot learning); (5) Break down complex tasks ‚Äî chain multiple simpler prompts instead of one giant request. Good prompts are clear, structured, and provide enough information for the model to succeed.",
      "metaphor": "It's like asking someone for dinner recommendations. Bad: 'Tell me about food.' (Too vague! Which food? For what occasion?) Good: 'Suggest 3 vegetarian restaurants in downtown Seattle, under $30 per person, open on Sundays, with outdoor seating.' The second prompt is specific (vegetarian), gives context (location, budget, day), sets format (3 suggestions), and defines constraints (outdoor seating). You'll get exactly what you need."
    },
    "training-vs-inference": {
      "title": "Training vs Inference",
      "simpleName": "School vs Work",
      "explanation": "Training is the expensive, one-time process of teaching the model by exposing it to billions of text examples, adjusting trillions of parameters over weeks or months. This costs millions of dollars and requires thousands of GPUs. Inference is the cheap, fast process of using the trained model to answer questions ‚Äî milliseconds per query, costing fractions of a cent. Training happens once; inference happens millions of times daily. The model weights are frozen during inference ‚Äî no learning happens when you chat with ChatGPT.",
      "metaphor": "Training is like going to medical school ‚Äî years of study, huge investment, learning from thousands of cases. Inference is like a doctor seeing patients ‚Äî quick consultations using knowledge already learned. The doctor doesn't relearn medicine for each patient; they apply existing expertise. Similarly, ChatGPT doesn't retrain when you ask a question; it applies patterns learned during training. One expensive education, millions of cheap applications."
    },
    "tokens": {
      "title": "Tokens",
      "simpleName": "Text Blocks",
      "explanation": "Tokens are the smallest units of text that AI models process. A token can be a word ('hello'), part of a word ('auto' + 'mobile'), or even a single character. English words average ~1.3 tokens; uncommon words may split into multiple tokens. Tokens matter because they determine: (1) Cost ‚Äî APIs charge per token; (2) Speed ‚Äî more tokens = slower processing; (3) Context limits ‚Äî models have maximum token capacity (e.g., 128K tokens = ~96K words). Understanding tokenization helps you optimize prompts and predict costs.",
      "metaphor": "Think of tokens as Lego blocks used to build sentences. Common words like 'the' or 'is' are single blocks. Longer or rare words like 'antidisestablishmentarianism' might be broken into several smaller blocks that snap together. The AI doesn't see letters; it sees these blocks. When you pay for API usage, you're paying per block, not per word. So efficient prompting means using fewer blocks to say the same thing."
    },
    "vectors": {
      "title": "Vectors (Embeddings)",
      "simpleName": "Meaning Map",
      "explanation": "Vectors (embeddings) represent words and concepts as lists of numbers in high-dimensional space. Similar meanings cluster together ‚Äî 'king' and 'queen' are close; 'king' and 'banana' are far apart. This numerical representation enables AI to perform semantic math: king - man + woman ‚âà queen. Modern models use 1,536+ dimensions. Vectors power semantic search, recommendations, and similarity matching. They're generated by neural networks trained to place related concepts near each other in this abstract space.",
      "metaphor": "Imagine every word has GPS coordinates, but in 1,536-dimensional space instead of just latitude/longitude. Words with similar meanings are geographically close. 'Happy' and 'joyful' might be neighbors at coordinates [0.2, 0.8, 0.3...]. 'Sad' is far away at [-0.5, -0.2, 0.1...]. When you search 'cheap flights,' the system finds documents near those coordinates in meaning-space, even if they use different words like 'affordable airfare.' Distance in this space = similarity in meaning."
    },
    "attention": {
      "title": "Attention Mechanism",
      "simpleName": "Focus",
      "explanation": "Attention lets models dynamically focus on relevant parts of the input when processing each word. When reading 'The cat sat on the mat,' the model can look back at 'cat' when processing 'it' later. Attention computes a weighted score for every word pair ‚Äî high scores mean strong relationship, low scores mean weak. Multi-head attention uses several parallel attention mechanisms to capture different types of relationships (syntax, semantics, etc.). This mechanism replaced older sequential models and enabled the transformer revolution.",
      "metaphor": "Imagine reading a sentence with a flashlight in a dark room. When you reach the word 'she,' you shine the light back to find who 'she' refers to ‚Äî maybe 'Maria' mentioned earlier. The brightness of the light (attention weight) is strongest on 'Maria' and dimmer on irrelevant words like 'the' or 'and.' The model does this for every word, simultaneously, building a web of relationships. That's attention: dynamically highlighting what matters for understanding each piece of text."
    },
    "prefill-decode": {
      "title": "Prefill vs Decode",
      "simpleName": "Reading vs Writing",
      "explanation": "LLM inference has two phases: (1) Prefill ‚Äî processing your entire input prompt in parallel, building the context representation. Fast, parallel computation. (2) Decode ‚Äî generating the response one token at a time, sequentially. Slow, each token depends on the previous ones. Prefill might take 50ms for a 1000-token prompt; decoding might take 50ms per token. This is why reading your question is instant but generating a long answer takes time. Optimizations like KV-caching speed up decoding by reusing computations.",
      "metaphor": "Think of prefill as reading a whole book page at once ‚Äî your eyes scan the entire page in seconds (parallel processing). Decoding is like handwriting a response, one letter at a time ‚Äî you can't write the 10th letter before the 9th (sequential). This is why ChatGPT 'understands' your long question instantly (prefill) but streams the answer slowly, word by word (decode). Reading is fast; writing takes time."
    },
    "context-windows": {
      "title": "Context Windows",
      "simpleName": "Working Memory",
      "explanation": "The context window is the maximum amount of text (in tokens) a model can process at once ‚Äî both your input and its output combined. GPT-3.5 has 4K tokens (~3K words); GPT-4 has 8K-128K; Claude has up to 200K. When you exceed the limit, older tokens get 'forgotten' ‚Äî they scroll out of the window. Larger windows enable longer conversations, bigger documents, and more context, but cost more and run slower. Managing context effectively is crucial for complex tasks.",
      "metaphor": "Think of the context window as RAM (working memory) in a computer. A model with a 4K token window is like having 4GB RAM ‚Äî fine for simple tasks, but you can't load huge files. A 200K window is like 64GB RAM ‚Äî you can work with entire books at once. When you exceed capacity, the system 'forgets' old data to make room for new. A chatbot with a small window might forget what you said 10 messages ago, just like you might forget details from a book's first chapter by the time you reach the end."
    },
    "hallucinations": {
      "title": "Hallucinations",
      "simpleName": "Confident Fabrications",
      "explanation": "Hallucinations occur when AI generates plausible-sounding but factually incorrect information. LLMs predict the next word based on patterns, not truth ‚Äî they don't access a fact database. If the model hasn't seen correct info or the question is ambiguous, it may 'fill in the blanks' with convincing nonsense. The danger: hallucinations are presented with the same confidence as facts. Mitigation strategies include RAG (grounding in real data), citations, fact-checking, and using smaller temperatures for factual tasks.",
      "metaphor": "Imagine asking a student a question they don't know the answer to. Instead of saying 'I don't know,' they confidently make up an answer that sounds right. 'Who invented the telephone?' ‚Äî 'Thomas Edison, in 1875, in Boston.' Sounds plausible! But it's wrong (Alexander Graham Bell, 1876). The student isn't lying; they're pattern-matching from partial knowledge. AI does the same: it generates statistically likely text, not verified truth. Always fact-check important claims, just like you would with a confident but unreliable student."
    },
    "transformers": {
      "title": "Transformers",
      "simpleName": "Master Architecture",
      "explanation": "Transformers are the neural network architecture that powers nearly all modern LLMs (GPT, Claude, Llama, etc.). Introduced in 2017, transformers revolutionized AI by enabling parallel processing and long-range dependencies through attention mechanisms. The architecture has two main components: multi-head attention (which words relate to which) and feed-forward layers (transformation and processing). Stacking dozens of these layers creates models with billions of parameters. Transformers replaced older sequential models (RNNs) and enabled the current AI boom.",
      "metaphor": "Think of transformers as the architectural innovation that enabled skyscrapers. Before steel-frame construction, buildings were limited to ~10 stories due to structural constraints. Steel frames changed everything ‚Äî suddenly you could build 100+ stories by stacking modular, reinforced units. Transformers did the same for AI: before them, models were limited by sequential processing (like brick-stacking). Transformers introduced parallel processing and attention (like steel frames), enabling massive scale. Now we stack 96 transformer layers to build GPT-4, just like stacking floors to build the Empire State Building."
    }
  },
  "conceptLevels": {
    "roots": {
      "name": "ROOTS",
      "subtitle": "Fundamental Mechanics",
      "description": "This is the AI 'engine'. Without understanding how the machine processes language, you're operating blind."
    },
    "trunk": {
      "name": "TRUNK",
      "subtitle": "Engineering & Architecture",
      "description": "The trunk is the supporting structure that holds everything else up."
    },
    "branches": {
      "name": "BRANCHES",
      "subtitle": "Applications & Agents",
      "description": "Branches are the practical application of knowledge."
    },
    "leaves": {
      "name": "LEAVES & FRUITS",
      "subtitle": "Research & Trends",
      "description": "This is the fastest-changing part of the tree. What is cutting-edge today is standard tomorrow."
    }
  },
  "codeSnippets": {
    "tokens": {
      "sampleText": "Hello, how are you?",
      "comment_load": "Load tokenizer for GPT-4",
      "comment_tokenize": "Tokenize text",
      "comment_decode": "Decode back to text"
    },
    "vectors": {
      "word1": "king",
      "word2": "queen",
      "word3": "banana",
      "comment_create": "Create embeddings",
      "comment_similarity": "Calculate similarity (cosine similarity)",
      "result1": "King vs Queen",
      "result2": "King vs Banana"
    },
    "attention": {
      "comment_simplified": "Simplified attention calculation",
      "comment_current": "Current word",
      "comment_previous": "Previous words",
      "comment_simplified2": "Simplified",
      "comment_scores": "Calculate attention scores",
      "word1": "Cat",
      "word2": "sat",
      "word3": "chair",
      "comment_apply": "Apply attention"
    },
    "ai-agents": {
      "comment_tools": "Define available tools",
      "comment_loop": "Agent loop",
      "userMessage": "What is the weather in London?",
      "toolResult_temp": "5¬∞C",
      "toolResult_cond": "cloudy",
      "comment_execute": "Execute tool",
      "comment_final": "Final answer"
    },
    "context-engineering": {
      "comment_poor": "Poor context - vague prompt",
      "poorPrompt": "Write an email",
      "systemPrompt": "You are a professional business communication specialist.\n      \n      Rules:\n      - Use a formal tone\n      - Keep emails short (max 150 words)\n      - Always include a CTA (call-to-action)\n      - Avoid jargon\n      \n      Format:\n      Greeting -> Context -> Main message -> CTA -> Closing",
      "userPrompt": "Write an email to a client asking about product delivery time"
    },
    "rag": {
      "comment_kb": "Knowledge base",
      "doc1": "The capital of Estonia is Tallinn.",
      "doc2": "Tallinn is located on the Gulf of Finland.",
      "doc3": "Python is a popular programming language.",
      "comment_query": "User query",
      "query": "What is the capital of Estonia?",
      "comment_retrieve": "1. Retrieve: Find relevant documents",
      "comment_augment": "2. Augment: Add context to prompt",
      "promptTemplate": "Context: {top_doc}\\n\\nQuestion: {query}",
      "comment_generate": "3. Generate: Get answer"
    },
    "function-calling": {
      "comment_define": "Define available functions",
      "toolDescription": "Get weather forecast for a city",
      "paramDescription": "City name",
      "comment_user": "User asks about weather",
      "userMessage": "What will the weather be like tomorrow in London?",
      "comment_decides": "Model decides to call function",
      "comment_execute": "Execute function (simulated)",
      "toolResult_temp": "8¬∞C",
      "toolResult_cond": "rainy",
      "comment_sendBack": "Send result back to model",
      "comment_getFinal": "Get final response"
    }
  },
  "codeExplanations": {
    "tokens": "This example shows how the tiktoken library converts text into tokens. Estonian words may require more tokens than English words.",
    "vectors": "Vectors convert words into numbers. Words with similar meanings (king/queen) are closer in space than different words (king/banana).",
    "attention": "The attention mechanism calculates the importance of each word relative to other words. Higher scores indicate stronger relationships.",
    "context-engineering": "Context engineering means creating a systematic environment: define the role, rules, format, and goal. This makes AI responses much more accurate and useful.",
    "rag": "RAG finds relevant documents (Retrieve), adds them to the prompt (Augment), and generates an answer (Generate). This allows AI to respond accurately based on company-specific data.",
    "ai-agents": "AI Agents use a loop: think ‚Üí choose tool ‚Üí execute ‚Üí check result ‚Üí repeat if needed. This enables autonomous task completion.",
    "function-calling": "Function calling allows the AI to 'decide' when to use external tools. The model generates a structured call, your application executes it, and the model uses the result to compose the final answer."
  },
  "learningPaths": {
    "title": "Learning Paths",
    "subtitle": "Curated journeys through AI concepts. Choose a path that matches your goals.",
    "backToHome": "Back to Home",
    "backToPaths": "All Learning Paths",
    "concepts": "concepts",
    "minutes": "min",
    "difficulty": "Difficulty",
    "beginner": "Beginner",
    "intermediate": "Intermediate",
    "advanced": "Advanced",
    "estimatedTime": "Estimated time",
    "prerequisites": "Prerequisites",
    "noPrerequisites": "No prerequisites",
    "startPath": "Start Learning",
    "continuePath": "Continue Learning",
    "completed": "Completed",
    "progress": "Progress",
    "conceptsCompleted": "{count} of {total} completed",
    "nextConcept": "Next up",
    "pathComplete": "Path complete!",
    "pathCompleteDesc": "You've completed all concepts in this learning path.",
    "exploreMore": "Explore more paths",
    "openConcept": "Open concept",
    "ai-fundamentals": {
      "title": "AI Fundamentals",
      "description": "Build a solid foundation. Understand tokens, vectors, attention, and how transformers work under the hood.",
      "longDescription": "This path takes you from zero to fluent in the core mechanics of modern AI. You'll learn how text becomes numbers, how models find meaning, and why transformers changed everything."
    },
    "prompt-engineering": {
      "title": "Prompt Engineering",
      "description": "Master the art of communicating with AI. Learn context windows, temperature control, and effective prompting strategies.",
      "longDescription": "Effective prompting is the most practical AI skill you can learn today. This path teaches you how models read your input, how to control creativity vs. precision, and how to structure prompts for consistent results."
    },
    "build-rag-apps": {
      "title": "Build RAG Applications",
      "description": "Learn to build AI apps that use your own data. From embeddings to retrieval-augmented generation.",
      "longDescription": "RAG is the most popular pattern for building enterprise AI applications. This path covers vector embeddings, context management, retrieval pipelines, and memory ‚Äî everything you need to build AI that knows your data."
    },
    "training-deep-dive": {
      "title": "Training Deep-Dive",
      "description": "Understand how AI models are trained ‚Äî from datasets and loss functions to backpropagation and evaluation.",
      "longDescription": "Go deeper into how models learn. This path covers the full training pipeline: data preparation, loss functions, backpropagation, epoch management, overfitting prevention, and model evaluation."
    },
    "career-explorer": {
      "title": "AI Career Explorer",
      "description": "Discover career paths in AI ‚Äî from prompt architect to ML engineer, data scientist to AI ethicist.",
      "longDescription": "AI is creating entirely new career paths. This path introduces five key roles ‚Äî AI Engineer, Prompt Architect, Data Scientist, AI Ethicist, and MLOps Specialist ‚Äî so you can find the one that fits your skills and interests."
    }
  },
  "connections": {
    "tabLabel": "Links",
    "youAreHere": "You are here",
    "positionInTree": "{current} of {total} in {level}",
    "buildsOn": "Builds on",
    "buildsOnEmpty": "Starting point ‚Äî no prerequisites needed.",
    "unlocks": "Unlocks",
    "unlocksEmpty": "Endpoint ‚Äî master this and explore freely.",
    "sameLevel": "Also in {level}",
    "whyLabel": "Why?",
    "learnMore": "Learn more",
    "conceptLinks": {
      "tokens": {
        "why": "Everything in AI starts with tokens. No tokens, no AI.",
        "whyTechnical": "LLMs operate on token sequences, not raw text. Tokenization determines cost, speed, and context capacity ‚Äî the fundamental unit of all model I/O."
      },
      "vectors": {
        "why": "Vectors give words meaning as numbers. This is how AI 'understands'.",
        "whyTechnical": "Embeddings map discrete tokens into continuous vector spaces where semantic similarity becomes geometric proximity ‚Äî enabling search, clustering, and analogical reasoning.",
        "fromTokens": "Tokens become vectors ‚Äî raw text pieces get numerical meaning."
      },
      "attention": {
        "why": "Attention lets AI focus on what matters in a sentence.",
        "whyTechnical": "Self-attention computes pairwise relevance scores across all token positions, enabling the model to capture long-range dependencies and contextual relationships in O(n¬≤) time.",
        "fromTokens": "Attention operates on token sequences to find relationships.",
        "fromVectors": "Attention uses vector representations to compute relevance scores between words."
      },
      "prefill-decode": {
        "why": "Why your question is instant but the answer streams slowly.",
        "whyTechnical": "Prefill processes the input prompt in parallel (GPU-efficient), while autoregressive decoding generates tokens sequentially ‚Äî creating the characteristic latency asymmetry in LLM inference.",
        "fromTokens": "Both phases process tokens ‚Äî prefill reads them in parallel, decode writes them one by one."
      },
      "context-windows": {
        "why": "The AI's working memory ‚Äî how much it can 'see' at once.",
        "whyTechnical": "Context window defines the maximum sequence length (in tokens) for combined input + output. Exceeding it causes information loss. Sizes range from 4K to 200K+ tokens across models.",
        "fromTokens": "Context windows are measured in tokens ‚Äî more tokens = bigger memory."
      },
      "hallucinations": {
        "why": "AI can be confidently wrong. Knowing this keeps you safe.",
        "whyTechnical": "Hallucinations arise from the autoregressive generation process ‚Äî models predict statistically likely continuations, not verified facts. Confidence scores don't correlate with factual accuracy.",
        "fromTokens": "Models predict the next token by probability ‚Äî not by checking facts."
      },
      "transformers": {
        "why": "The architecture behind GPT, Claude, and every modern AI model.",
        "whyTechnical": "Transformers stack multi-head self-attention with feed-forward layers, enabling parallel processing and scalability to billions of parameters ‚Äî replacing sequential RNN/LSTM architectures.",
        "fromAttention": "Multi-head attention is the core mechanism inside every transformer layer.",
        "fromVectors": "Transformers process token embeddings (vectors) through attention layers."
      },
      "training-vs-inference": {
        "why": "Training costs millions. Using the model costs fractions of a cent.",
        "whyTechnical": "Training adjusts model weights via backpropagation over massive datasets (weeks, thousands of GPUs). Inference is a forward pass with frozen weights (milliseconds, minimal compute).",
        "fromTokens": "Training processes trillions of tokens. Inference processes your tokens."
      },
      "temperature-sampling": {
        "why": "The dial between 'safe and predictable' and 'creative chaos'.",
        "whyTechnical": "Temperature scales the logit distribution before softmax ‚Äî low values sharpen probabilities toward the argmax, high values flatten toward uniform. Top-k/top-p further constrain the sampling space.",
        "fromTokens": "Temperature controls which token gets picked from the probability distribution."
      },
      "prompting-basics": {
        "why": "The single most practical AI skill: asking better questions.",
        "whyTechnical": "Effective prompting exploits in-context learning by structuring input to activate relevant model capabilities ‚Äî specificity, format constraints, and few-shot examples dramatically improve output quality.",
        "fromTokens": "Every word in your prompt is tokens that the model processes ‚Äî precision saves cost and improves output."
      },
      "context-engineering": {
        "why": "Not just the question ‚Äî the entire environment you build for the AI.",
        "whyTechnical": "Context engineering systematically constructs the full input: system role, constraints, output format, examples, and user query ‚Äî maximizing the information density within the context window.",
        "fromTokens": "Every part of your engineered context consumes tokens from the window budget."
      },
      "rag": {
        "why": "AI that can search your documents before answering. Grounded, not guessing.",
        "whyTechnical": "RAG pipelines: (1) embed the query, (2) retrieve top-K documents via vector similarity search, (3) augment the prompt with retrieved context, (4) generate a grounded response with source attribution.",
        "fromVectors": "RAG uses vector search to find relevant documents by meaning, not keywords.",
        "fromMemory": "RAG extends short-term context with long-term document retrieval."
      },
      "memory": {
        "why": "Short-term (conversation) vs long-term (database). AI needs both.",
        "whyTechnical": "Short-term: bounded by context window tokens. Long-term: external vector stores with semantic retrieval, enabling cross-session persistence, fact storage, and preference tracking.",
        "fromVectors": "Long-term memory stores and retrieves information as vectors for semantic search."
      },
      "lora": {
        "why": "Customize a model for your domain at 1% of the cost.",
        "whyTechnical": "LoRA injects trainable low-rank decomposition matrices (A√óB) alongside frozen weights. By training only ~0.1% of parameters, it achieves near-full-fine-tuning performance at a fraction of compute.",
        "fromVectors": "LoRA adapters modify how the model transforms input vectors through its layers.",
        "fromAttention": "LoRA typically targets attention weight matrices (Q, K, V projections) for maximum impact."
      },
      "security": {
        "why": "Input attacks, model poisoning, output risks. Three layers to protect.",
        "whyTechnical": "Defense-in-depth: input validation (injection prevention), model hardening (alignment, RLHF), output filtering (guardrails, content classification). No single defense suffices.",
        "fromTokens": "Prompt injection attacks exploit how models process input tokens."
      },
      "ai-agents": {
        "why": "AI that doesn't just answer ‚Äî it acts. Observe, think, execute.",
        "whyTechnical": "Agents implement the observe-reason-act loop: parse environment state, plan via chain-of-thought reasoning, execute actions through tool calls, evaluate results, and iterate until task completion.",
        "fromContextEngineering": "Agents need carefully engineered system prompts to define their role, tools, and boundaries.",
        "fromRag": "Agents use RAG to access knowledge bases when they need information to complete tasks."
      },
      "mcp": {
        "why": "One protocol to connect any AI to any tool. Like USB-C for AI.",
        "whyTechnical": "MCP standardizes the AI-tool interface: tool discovery, parameter schemas, authentication, and execution ‚Äî eliminating per-integration custom code across model providers.",
        "fromAiAgents": "MCP provides the standard interface that agents use to connect to external tools."
      },
      "complexity-levels": {
        "why": "LLM ‚Üí Reasoning Model ‚Üí Agent. Three tiers of AI capability.",
        "whyTechnical": "Tier progression: (1) single-pass next-token prediction, (2) multi-step chain-of-thought with verification, (3) autonomous tool-using agents with memory and decision loops.",
        "fromTokens": "All three levels process tokens ‚Äî the difference is how many reasoning steps happen between input and output."
      },
      "function-calling": {
        "why": "Giving the AI hands ‚Äî it can call APIs, query databases, send emails.",
        "whyTechnical": "The model generates structured function call JSON (name + parameters). Your application executes the call, returns results, and the model incorporates them into its response ‚Äî bridging LLM reasoning with real-world actions.",
        "fromAiAgents": "Function calling is the mechanism agents use to interact with the real world."
      },
      "moe": {
        "why": "8 expert models, but only 2 activate per question. Fast and cheap.",
        "whyTechnical": "Sparse MoE routes each token through a learned gating network to K-of-N expert sub-networks. Only activated experts consume compute ‚Äî enabling massive model capacity with sub-linear inference cost.",
        "fromAttention": "Each expert applies its own attention and feed-forward layers to the routed tokens.",
        "fromVectors": "The routing network uses input vector representations to select the best experts."
      },
      "reasoning-models": {
        "why": "AI that thinks step-by-step before answering. Slower but more reliable.",
        "whyTechnical": "Reasoning models use internal chain-of-thought: generating intermediate reasoning tokens, self-verification, and backtracking before producing the final answer ‚Äî trading latency for accuracy on complex tasks.",
        "fromAttention": "Extended reasoning requires processing many more attention steps internally.",
        "fromContextEngineering": "Reasoning models benefit from well-structured prompts that define the problem space clearly."
      },
      "green-ai": {
        "why": "Same quality AI, 90% less energy. Efficiency is the next frontier.",
        "whyTechnical": "Techniques: model distillation (teacher‚Üístudent), quantization (FP16‚ÜíINT4), efficient architectures (MoE), and optimized inference (batching, KV-cache) ‚Äî reducing compute cost and carbon footprint.",
        "fromTokens": "Processing fewer tokens and using smaller models dramatically cuts energy consumption.",
        "fromAttention": "Efficient attention variants (flash attention, sparse attention) are key to Green AI."
      },
      "agi-asi": {
        "why": "From narrow AI (today) to general intelligence (future?) to beyond.",
        "whyTechnical": "AGI: human-level performance across all cognitive domains. ASI: surpassing human capability in every dimension. Current systems remain narrow ‚Äî excelling at specific tasks while lacking general reasoning and common sense.",
        "fromAiAgents": "Agents represent the closest step toward general capability ‚Äî autonomous, multi-tool reasoning.",
        "fromAttention": "Scaling attention mechanisms is one path researchers explore toward more general intelligence."
      }
    }
  },
  "upNext": {
    "title": "Up Next",
    "sameLevel": "Continue in this level",
    "nextLevel": "Next level",
    "prerequisiteFor": "Unlocks",
    "allDone": "You've explored all concepts!",
    "allDoneDesc": "Great job! Browse the tree to revisit any concept.",
    "browseTree": "Browse Tree"
  },
  "celebration": {
    "levelComplete": "Level Complete!",
    "levelCompleteDesc": "You've completed all {count} concepts in {level}.",
    "allComplete": "Tree Complete!",
    "allCompleteDesc": "You've explored all {count} concepts. You've grown from roots to leaves!",
    "nextLevel": "Continue to {level}",
    "shareProgress": "Share Progress",
    "keepExploring": "Keep Exploring",
    "awesome": "Awesome!",
    "certificate": "Certificate of Completion"
  },
  "dna": {
    "header": {
      "title": "The Mechanism",
      "subtitle": "Every AI thought follows the same 4-step journey. From raw text to meaning, and back again."
    },
    "input": {
      "placeholder": "Type anything (e.g. 'Why is the sky blue?')",
      "interactiveMode": "INTERACTIVE MODE",
      "status": "STATUS: {step}...",
      "reset": "Reset simulation",
      "confirmReset": "Tap again to reset"
    },
    "card": {
      "deepDive": "DEEP DIVE ‚Üí",
      "learnMore": "Learn more about {step} ‚Üí",
      "helpTooltip": "What is this step?"
    },
    "steps": {
      "complete": {
        "tokenization": "Text tokenized! Each piece has a unique ID.",
        "vectorizing": "Tokens vectorized! Similar words cluster together.",
        "attention": "Attention mapped! See which words connect.",
        "prediction": "Prediction complete! Check the top candidate."
      },
      "hint": {
        "attention": "Tap a token to see its connections"
      }
    },
    "nav": {
      "next": "Next",
      "finish": "Finish",
      "done": "Done",
      "playing": "Playing",
      "paused": "Paused",
      "stepOf": "Step {current} of {total}",
      "stepName": {
        "tokenization": "Tokenize",
        "vectorizing": "Vectorize",
        "attention": "Attention",
        "prediction": "Predict"
      },
      "thicknessLabel": "thickness = importance",
      "tapToSpotlight": "tap a word to spotlight connections",
      "connections": "{count} connections"
    },
    "seed": {
      "growing": "Growing into the Tree...",
      "exploring": "Exploring deeper..."
    },
    "microLesson": {
      "metaphorLabel": "Metaphor",
      "resumeFlow": "Resume Flow",
      "exploreMore": "Explore More",
      "tokenization": {
        "title": "Tokenization",
        "body": "Words broken into pieces. Language models don't read words like we do ‚Äî they break text into 'tokens', small chunks that become the basic units of meaning.",
        "metaphor": "Like chopping a sentence into LEGO bricks."
      },
      "vectorizing": {
        "title": "Embeddings (Vectors)",
        "body": "Meaning as numbers. Each token is converted into a list of numbers representing its meaning in a multi-dimensional space.",
        "metaphor": "Like giving each word a GPS coordinate in a universe of meaning."
      },
      "attention": {
        "title": "Attention",
        "body": "Connecting the dots. The model looks at all tokens at once and decides which ones are related, paying attention to relevant context regardless of distance.",
        "metaphor": "Like connecting dots with threads of varying thickness."
      },
      "prediction": {
        "title": "Prediction",
        "body": "Guessing the next word. Based on all previous context, the model calculates the probability of the next token and picks one.",
        "metaphor": "Like guessing the end of a sentence before it's spoken."
      }
    },
    "completion": {
      "title": "Simulation Complete",
      "subtitle": "You've explored the 4-step journey from text to prediction.",
      "predicted": "Winner Prediction",
      "replay": "Replay Steps",
      "explore": "Plant a Seed"
    },
    "controlHint": "Move cursor to slow down ¬∑ Click cards to explore",
    "seedPath": {
      "title": "Plant Your Seed",
      "subtitle": "Choose your path to understanding AI",
      "builder": {
        "label": "Builder",
        "description": "I want to build AI apps"
      },
      "thinker": {
        "label": "Thinker",
        "description": "I want to understand AI"
      },
      "explorer": {
        "label": "Explorer",
        "description": "I'm just browsing"
      }
    },
    "mobile": {
      "swipeHint": "Swipe to explore steps",
      "cardOf": "Step {current} of {total}",
      "tapToExplore": "Tap card to explore"
    }
  },
  "programs": {
    "catalog": {
      "title": "Choose Your Path",
      "subtitle": "From understanding the mechanism to building automation. Select the program that fits your goals.",
      "duration": "Duration",
      "weeks": "Weeks",
      "effort": "Effort",
      "totalHours": "h Total",
      "viewDetails": "View Details",
      "bestValue": "Best Value",
      "compare": "Compare Programs",
      "compareFeature": "Feature",
      "comparePrice": "Price",
      "compareDuration": "Duration",
      "compareHours": "Hours",
      "compareLevel": "Level"
    },
    "hero": {
      "apply": "Apply Now",
      "weeks": "weeks",
      "hours": "hours"
    },
    "features": {
      "heading": "What You'll Learn"
    },
    "curriculum": {
      "heading": "Week-by-Week Curriculum",
      "subtitle": "A structured journey from foundation to mastery",
      "week": "Week"
    },
    "pricing": {
      "heading": "Invest in",
      "headingAccent": "Your Future",
      "benefits": [
        "Lifetime access to course materials",
        "Certificate of completion",
        "Community access & networking",
        "Hands-on projects & exercises"
      ],
      "guarantee": "30-Day Guarantee",
      "guaranteeDesc": "Not satisfied? Full refund within 30 days, no questions asked.",
      "totalInvestment": "Total Investment",
      "vatNote": "VAT not included",
      "flexiblePayment": "Flexible payment available",
      "cta": "Enroll Now",
      "paymentNote": "Secure payment. Start learning immediately.",
      "graduateDiscount": "Graduate Discount"
    },
    "faq": {
      "heading": "Frequently Asked Questions"
    },
    "lead": {
      "title": "Secure Your Spot",
      "subtitle": "Leave your details and we'll reach out with next steps.",
      "name": "Full Name",
      "namePlaceholder": "John Doe",
      "email": "Email Address",
      "emailPlaceholder": "john@example.com",
      "phone": "Phone (optional)",
      "phonePlaceholder": "+372 ...",
      "notes": "Goals or Questions (optional)",
      "notesPlaceholder": "What do you hope to get out of this program?",
      "submit": "Reserve My Spot",
      "submitting": "Submitting...",
      "successTitle": "Welcome to the Tribe!",
      "successMessage": "We've received your application. Check your email ‚Äî we'll be in touch within 24 hours.",
      "successClose": "Got It",
      "errorGeneric": "Something went wrong. Please try again.",
      "errorEmail": "Please enter a valid email address.",
      "errorName": "Please enter your name.",
      "close": "Close"
    }
  },
  "nav": {
    "tree": "Tree",
    "mechanism": "Mechanism",
    "learn": "Programs",
    "proto": "Proto",
    "back": "Back",
    "settings": "Settings"
  },
  "stages": {
    "dna": "DNA",
    "seed": "Seed",
    "sprout": "Sprout",
    "tree": "Tree",
    "fruits": "Fruits",
    "orchard": "Orchard",
    "description": {
      "dna": "The Mechanism ‚Äî How AI processes text",
      "seed": "Your Intent ‚Äî What do you want to explore?",
      "sprout": "Foundations ‚Äî 6 essential AI concepts",
      "tree": "Knowledge ‚Äî Deep dive into all concepts",
      "fruits": "Applications ‚Äî What can AI do for you?",
      "orchard": "Career Harvest ‚Äî Professional paths in AI"
    }
  },
  "floatingInput": {
    "placeholder": "Ask anything about AI...",
    "expand": "Expand input",
    "collapse": "Collapse input",
    "submit": "Ask"
  },
  "fruits": {
    "title": "The Harvest",
    "subtitle": "Where intelligence bears fruit. Explore the practical applications and value generated by the AI system.",
    "phaseLabel": "Phase III: Application",
    "inputPlaceholder": "Search applications...",
    "card": {
      "visitApp": "Launch App"
    }
  },
  "seed": {
    "title": "The Training",
    "subtitle": "Deep underground, raw data is compressed under intense heat into the seed of intelligence.",
    "phaseLabel": "Phase I: The Seed",
    "inputPlaceholder": "Query the training data...",
    "card": {
      "learnMore": "Analyze Process"
    },
    "steps": {
      "dataset": {
        "title": "The Dataset",
        "desc": "Raw information collected from the world. This is the soil."
      },
      "training": {
        "title": "Training (Compression)",
        "desc": "The intense process of compressing data into weights. Maximizing pattern recognition."
      },
      "model": {
        "title": "The Model",
        "desc": "The final compressed artifact. A static file ready to be 'woken up'."
      }
    }
  },
  "orchard": {
    "title": "Career Paths",
    "subtitle": "Cultivate your future. Explore the professional opportunities growing in the AI ecosystem.",
    "phaseLabel": "Phase IV: The Orchard",
    "inputPlaceholder": "Enter your skills...",
    "yourPath": "Your Path?",
    "growingField": "The field is growing every day.",
    "card": {
      "viewPath": "View Career Path"
    }
  }
}