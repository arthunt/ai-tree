{
  "version": "1.0.0",
  "metadata": {
    "title": "AI Teadmiste Puu (AI Knowledge Tree)",
    "description": "Terviklik raamistik AI kontseptide õpetamiseks",
    "created": "2025-12-04",
    "language": "et"
  },
  "levels": [
    {
      "id": "roots",
      "name": "JUURED",
      "subtitle": "Fundamentaalne Mehaanika",
      "description": "See on AI 'mootor'. Ilma mõistmata, kuidas masin keelt töötleb, tegutsed pimesi.",
      "color": "#065f46",
      "order": 1
    },
    {
      "id": "trunk",
      "name": "TÜVI",
      "subtitle": "Inseneeria ja Arhitektuur",
      "description": "Tüvi on kandev struktuur, mis toetab kõike muud.",
      "color": "#92400e",
      "order": 2
    },
    {
      "id": "branches",
      "name": "OKSAD",
      "subtitle": "Rakendamine ja Agendid",
      "description": "Oksad on teadmiste praktiline rakendamine.",
      "color": "#3b82f6",
      "order": 3
    },
    {
      "id": "leaves",
      "name": "LEHED JA VILJAD",
      "subtitle": "Uuringud ja Trendid",
      "description": "See on puu kõige kiiremini muutuv osa. Mis on täna tippteadus, on homme standard.",
      "color": "#8b5cf6",
      "order": 4
    }
  ],
  "concepts": [
    {
      "id": "moe",
      "level": "leaves",
      "title": "Mixture of Experts (MOE)",
      "simpleName": "Konsiilium",
      "explanation": "Tavalises AI mudelis töötlevad kõik osad igat küsimust. MOE mudelis on palju väiksemaid 'eksperte', kellest igaüks on spetsialiseerunud teatud teemale. Kui esitate küsimuse, valib mudel automaatselt 2-3 parimat eksperti selle küsimuse jaoks. See teeb mudeli kiiremaks ja säästab raha, sest kogu mudelit ei pea aktiveerida.",
      "metaphor": "Arstide konsiilium. Selle asemel, et üks perearst püüaks kõike teada, suunatakse sind kardioloogi või neuroloogi juurde. Iga arst keskendub ühele valdkonnale ja on seal ekspert.",
      "icon": "users",
      "complexity": 2,
      "prerequisites": ["attention", "vectors"]
    },
    {
      "id": "agi-asi",
      "level": "leaves",
      "title": "AGI ja ASI",
      "simpleName": "Superintellekt",
      "explanation": "Teekond inimtaseme intellekti (AGI) ja superintellekti (ASI) suunas. Mudelid, mis suudavad üldistada ja ületada inimvõimeid kõigis valdkondades.",
      "metaphor": "Üliõpilane vs Einstein vs Superintellekt. Tänane AI on nagu tark tudeng. AGI on nagu geenius. ASI on midagi, mis ületab inimlikud võimed kõigis valdkondades.",
      "icon": "brain",
      "complexity": 3,
      "prerequisites": ["ai-agents", "attention"]
    },
    {
      "id": "green-ai",
      "level": "leaves",
      "title": "Green AI (Jätkusuutlikkus)",
      "simpleName": "Roheline AI",
      "explanation": "Fookus energiatõhususele. Kuidas treenida ja jooksutada mudeleid väiksema süsiniku jalajäljega.",
      "metaphor": "Elektriauto. Sama sihtkoht (tulemus), aga kütusekulu ja keskkonnakahju on kordades väiksem.",
      "icon": "leaf",
      "complexity": 2,
      "prerequisites": ["tokens", "attention"]
    },
    {
      "id": "reasoning-models",
      "level": "leaves",
      "title": "Spetsialiseeritud Arutlusmudelid",
      "simpleName": "Mõtleja",
      "explanation": "Tavalised AI mudelid vastavad kiiresti. Arutlusmudelid (nagu OpenAI o1) on treenitud 'aeglaselt mõtlema'. Nad lahendavad probleemi samm-sammult, kontrollivad oma tööd ja parandavad vigu. See teeb need paremaks matemaatikas, programmeerimises ja loogikaülesannetes.",
      "metaphor": "Maletaja vs kiirmale. Kiirmales vastab sa koheselt (nagu tavaline AI). Tõsises maleturniiri mõtled sa 5-10 minutit, kaalud erinevaid käike, kujutad tulevikku ette. Arutlusmudel töötab samamoodi - aeglasem, aga parem tulemuse.",
      "icon": "chess-knight",
      "complexity": 2,
      "prerequisites": ["attention", "context-engineering"]
    },
    {
      "id": "ai-agents",
      "level": "branches",
      "title": "AI Agendid",
      "simpleName": "Tegija",
      "explanation": "Autonoomsed süsteemid, mis mitte ainult ei räägi, vaid tegutsevad: kasutavad tööriistu, planeerivad ja täidavad ülesandeid iseseisvalt.",
      "metaphor": "Töömees vs Konsultant. Konsultant (LLM) annab nõu. Töömees (Agent) võtab haamri ja parandab katuse ära.",
      "icon": "bot",
      "complexity": 2,
      "prerequisites": ["context-engineering", "rag"],
      "codeExample": {
        "language": "python",
        "code": "from openai import OpenAI\nimport json\n\nclient = OpenAI()\n\n# Define available tools\ntools = [{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"get_weather\",\n        \"description\": \"Get weather for a city\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"city\": {\"type\": \"string\"}\n            },\n            \"required\": [\"city\"]\n        }\n    }\n}]\n\n# Agent loop\nmessages = [{\"role\": \"user\", \"content\": \"Mis ilm on Tallinnas?\"}]\n\nwhile True:\n    response = client.chat.completions.create(\n        model=\"gpt-4\", messages=messages, tools=tools\n    )\n    message = response.choices[0].message\n    \n    if message.tool_calls:\n        # Execute tool\n        tool_call = message.tool_calls[0]\n        result = json.dumps({\"temperature\": \"5°C\", \"condition\": \"pilvine\"})\n        messages.append({\"role\": \"tool\", \"content\": result, \"tool_call_id\": tool_call.id})\n    else:\n        # Final answer\n        print(message.content)\n        break",
        "explanation": "AI Agent kasutab tsüklit: mõtle -> vali tööriist -> täida -> kontrolli tulemust -> korda vajaduse korral. See võimaldab autonoomselt ülesandeid lahendada."
      }
    },
    {
      "id": "mcp",
      "level": "branches",
      "title": "MCP (Model Context Protocol)",
      "simpleName": "Ühendaja",
      "explanation": "MCP on ühtne standard, mis võimaldab AI-del suhelda erinevate programmide ja andmebaasidega. Enne MCP-d pidi iga ühendus eraldi programmeerima. Nüüd on üks ühine 'keel', mida kõik mõistavad. AI saab lihtsalt küsida: 'Anna mulle andmed kliendist X' ja andmebaas vastab õigesti.",
      "metaphor": "USB-C kaabel. Vanasti oli igal seadmel erinev pistik (frustreeriv!). USB-C on universaalne - sobib kõigile. Samamoodi MCP ühendab AI ükskõik millise andmebaasi või programmiga ilma spetsiaalse koodita.",
      "icon": "plug",
      "complexity": 2,
      "prerequisites": ["ai-agents"]
    },
    {
      "id": "complexity-levels",
      "level": "branches",
      "title": "3 Keerukuse taset",
      "simpleName": "Kolm taset",
      "explanation": "1. LLM (jutustaja), 2. Arutlusmudel (mõtleja), 3. Agent (tegija).",
      "metaphor": "Köögimetafoor: 1. Retseptiraamat (LLM), 2. Peakokk, kes koostab menüü (Arutlus), 3. Kokk, kes reaalselt hakib ja küpsetab (Agent).",
      "icon": "layers",
      "complexity": 1,
      "prerequisites": ["tokens"]
    },
    {
      "id": "context-engineering",
      "level": "trunk",
      "title": "Kontekstitehnika (Context Engineering)",
      "simpleName": "Lavastus",
      "explanation": "Lihtne prompt on lühike küsimus. Kontekstitehnika tähendab kogu keskkonna loomist AI-le: määrata roll ('Sa oled professionaalne e-maili kirjutaja'), anda reeglid (kasuta formaalset tooni), seada formaat (alusta tervitusega), anda näiteid. Mida parem kontekst, seda parem tulemus.",
      "metaphor": "Lavastaja töö. Prompt on nagu näitleja üks lause. Kontekst on kogu lavastus: lavakujundus, valgus, kostüümid, taustamuusika ja roll, mida näitleja mängib. Kõik see koos annab lausele tähenduse ja emotsiooni.",
      "icon": "stage",
      "complexity": 2,
      "prerequisites": ["tokens"],
      "codeExample": {
        "language": "javascript",
        "code": "const openai = new OpenAI();\n\n// Poor context - vague prompt\nconst poorResponse = await openai.chat.completions.create({\n  model: \"gpt-4\",\n  messages: [\n    { role: \"user\", content: \"Kirjuta e-mail\" }\n  ]\n});\n\n// Rich context engineering\nconst richResponse = await openai.chat.completions.create({\n  model: \"gpt-4\",\n  messages: [\n    {\n      role: \"system\",\n      content: `Sa oled professionaalne ärikommunikatsiooni spetsialist.\n      \n      Reeglid:\n      - Kasuta formaalset tooni\n      - Hoia e-mailid lühikesed (max 150 sõna)\n      - Lisa alati CTA (call-to-action)\n      - Väldi žargooni\n      \n      Formaat:\n      Tervitus -> Kontekst -> Peamine sõnum -> CTA -> Lõpetus`\n    },\n    {\n      role: \"user\",\n      content: \"Kirjuta e-mail kliendile, kes küsib toote tarneaja kohta\"\n    }\n  ]\n});\n\nconsole.log(richResponse.choices[0].message.content);",
        "explanation": "Kontekstitehnika tähendab süsteemse keskkonna loomist: määra roll, reeglid, formaat ja eesmärk. See muudab AI vastused palju täpsemaks ja kasulikumaks."
      }
    },
    {
      "id": "rag",
      "level": "trunk",
      "title": "RAG (Retrieval-Augmented Generation)",
      "simpleName": "Raamatukogu",
      "explanation": "RAG võimaldab AI-l vastata täpsemalt, andes talle ligipääsu konkreetsele teabele. Esimeseks otsitakse asjakohased dokumendid ettevõtte andmebaasist (Retrieval). Seejärel lisatakse need dokumendid küsimusele juurde (Augmented). Lõpuks genereerib AI vastuse nende dokumentide põhjal (Generation). Nii väheneb vale info andmine.",
      "metaphor": "Avatud raamatuga eksam. Tavaline AI vastab peast (võib eksida). RAG laseb AI-l enne vastamist õpikus järele vaadata. Tulemus on täpsem ja usaldusväärsem.",
      "icon": "book-open",
      "complexity": 2,
      "prerequisites": ["vectors", "memory"],
      "codeExample": {
        "language": "python",
        "code": "from openai import OpenAI\nimport numpy as np\n\nclient = OpenAI()\n\n# Knowledge base\ndocuments = [\n    \"Eesti pealinn on Tallinn.\",\n    \"Tallinn asub Soome lahe ääres.\",\n    \"Python on populaarne programmeerimiskeel.\"\n]\n\n# User query\nquery = \"Mis on Eesti pealinn?\"\n\n# 1. Retrieve: Find relevant documents\nquery_emb = client.embeddings.create(\n    model=\"text-embedding-3-small\", input=query\n).data[0].embedding\n\nrelevant_docs = []\nfor doc in documents:\n    doc_emb = client.embeddings.create(\n        model=\"text-embedding-3-small\", input=doc\n    ).data[0].embedding\n    similarity = np.dot(query_emb, doc_emb)\n    relevant_docs.append((doc, similarity))\n\ntop_doc = max(relevant_docs, key=lambda x: x[1])[0]\n\n# 2. Augment: Add context to prompt\nprompt = f\"Kontekst: {top_doc}\\n\\nKüsimus: {query}\"\n\n# 3. Generate: Get answer\nresponse = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[{\"role\": \"user\", \"content\": prompt}]\n)\nprint(response.choices[0].message.content)",
        "explanation": "RAG leiab asjakohaseid dokumente (Retrieve), lisab need prompti (Augment) ja genereerib vastuse (Generate). Nii saab AI vastata täpselt ettevõtte andmete põhjal."
      }
    },
    {
      "id": "memory",
      "level": "trunk",
      "title": "Mälu ja Olekuhaldus",
      "simpleName": "Mälu",
      "explanation": "AI peab meeles pidama, mida varem rääkisite. On kahte tüüpi mälu: LÜHIAJALINE MÄLU ehk 'vestluse aken' - see on piiratud (näiteks viimased 10 sõnumit). PIKAAJALINE MÄLU - olulised faktid salvestatakse andmebaasi, et AI saaks neid hiljem kasutada. Ilma mäluta alustaks AI iga sõnumiga nullist.",
      "metaphor": "Märkmik. Kui teil on halb mälu, kirjutate olulise üles. AI-l on 'lühimälu' nagu paberi kulu (piiratud ruum) ja 'pikk mälu' nagu süstemaatiline märkmik (saab hiljem üles leida).",
      "icon": "notebook",
      "complexity": 2,
      "prerequisites": ["vectors"]
    },
    {
      "id": "lora",
      "level": "trunk",
      "title": "LoRA & Peenhäälestus",
      "simpleName": "Täiendkoolitus",
      "explanation": "Peenhäälestus tähendab AI mudeli kohandamist konkreetsele ülesandele. LoRA on nutikas meetod, mis õpetab mudelile uusi oskusi, muutmata kogu mudelit. See on nagu lisada mudelile väikesi märkmeid, mis juhendavad, kuidas mingis olukorras käituda. Palju kiirem ja odavam kui terve mudeli uuesti treenimine.",
      "metaphor": "Kursused. Ülikooli lõpetanu (baasmudel) läheb lühikursusele, et saada spetsialistiks kitsal alal (näiteks meditsiinitekstid). Ta ei pea uuesti kogu ülikooli käima, vaid õpib lihtsalt ühte valdkonda süvitsi.",
      "icon": "graduation-cap",
      "complexity": 3,
      "prerequisites": ["vectors", "attention"]
    },
    {
      "id": "security",
      "level": "trunk",
      "title": "AI Turvalisus",
      "simpleName": "Turvalisus",
      "explanation": "Meetmed prompt injection'i ja andmelekete vastu. 'Tulemüür' AI ja maailma vahel.",
      "metaphor": "Turvamees ööklubis. Kontrollib, kes tohib sisse tulla (sisend) ja mida tohib välja viia (väljund).",
      "icon": "shield",
      "complexity": 2,
      "prerequisites": ["tokens"]
    },
    {
      "id": "tokens",
      "level": "roots",
      "title": "Tokenid",
      "simpleName": "Tekstiklotsid",
      "explanation": "Teksti väikseimad ühikud AI jaoks. See ei ole sõna, vaid täheühend. Need määravad hinna ja kiiruse.",
      "metaphor": "Lego klotsid. Sõna 'Banaan' ei ole üks tükk, vaid koosneb kolmest klotsist. AI ehitab lauseid klots-klotsi haaval.",
      "icon": "blocks",
      "complexity": 1,
      "codeExample": {
        "language": "python",
        "code": "import tiktoken\n\n# Load tokenizer for GPT-4\nencoding = tiktoken.encoding_for_model(\"gpt-4\")\n\n# Tokenize text\ntext = \"Tere, kuidas sul läheb?\"\ntokens = encoding.encode(text)\n\nprint(f\"Text: {text}\")\nprint(f\"Tokens: {tokens}\")\nprint(f\"Token count: {len(tokens)}\")\n\n# Decode back to text\ndecoded = encoding.decode(tokens)\nprint(f\"Decoded: {decoded}\")",
        "explanation": "Näide näitab, kuidas tiktoken teek muudab teksti tokeniteks. Eestikeelsed sõnad võivad vajada rohkem tokeneid kui ingliskeelsed."
      }
    },
    {
      "id": "vectors",
      "level": "roots",
      "title": "Vektorid (Embeddings)",
      "simpleName": "Tähenduste kaart",
      "explanation": "AI ei mõista sõnu otse, vaid tõlgib need numbriteks. Vektorid on numbrilistest muudavad sõnad numbrilisteks punktideks ruumis. Sarnase tähendusega sõnad pannakse lähedale kokku, erinevad sõnad kaugele. Nii saab AI aru, et 'kuningas' ja 'kuninganna' on sarnased, aga 'banaan' on hoopis erinev.",
      "metaphor": "GPS koordinaadid. Sõna 'Kuningas' ja 'Kuninganna' asuvad kaardil lähestikku (nagu Tallinn ja Tartu), aga 'Banaan' on teisel mandril. AI mõõdab tähenduste vahemaad nagu GPS kaardil.",
      "icon": "map-pin",
      "complexity": 2,
      "prerequisites": ["tokens"],
      "codeExample": {
        "language": "python",
        "code": "from openai import OpenAI\nimport numpy as np\n\nclient = OpenAI()\n\n# Create embeddings\ntexts = [\"kuningas\", \"kuninganna\", \"banaan\"]\nembeddings = []\n\nfor text in texts:\n    response = client.embeddings.create(\n        model=\"text-embedding-3-small\",\n        input=text\n    )\n    embeddings.append(response.data[0].embedding)\n\n# Calculate similarity (cosine similarity)\ndef cosine_similarity(a, b):\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\nprint(f\"Kuningas vs Kuninganna: {cosine_similarity(embeddings[0], embeddings[1]):.3f}\")\nprint(f\"Kuningas vs Banaan: {cosine_similarity(embeddings[0], embeddings[2]):.3f}\")",
        "explanation": "Vektorid muudavad sõnad numbriteks. Lähedase tähendusega sõnad (kuningas/kuninganna) on ruumis lähemal kui erinevad sõnad (kuningas/banaan)."
      }
    },
    {
      "id": "attention",
      "level": "roots",
      "title": "Tähelepanu (Attention Mechanism)",
      "simpleName": "Fookus",
      "explanation": "Kui AI loeb lauset, ta ei võta kõiki sõnu võrdselt. Tähelepanu mehhanism aitab AI-l aru saada, millised sõnad on üksteisega seotud. Näiteks lauses 'Mari läks poodi ja ta ostis piima' aitab see mõista, et 'ta' viitab Marile.",
      "metaphor": "Taskulamp pimedas toas. AI valgustab korraga ainult neid sõnu, mis on hetkel vastuse andmiseks olulised. Teine sõna 'Mari' särab eredamalt, kui AI mõtleb sõna 'ta' peale.",
      "icon": "flashlight",
      "complexity": 2,
      "prerequisites": ["tokens", "vectors"],
      "codeExample": {
        "language": "python",
        "code": "import torch\nimport torch.nn.functional as F\n\n# Simplified attention calculation\nquery = torch.tensor([[1.0, 0.5]])  # Current word\nkeys = torch.tensor([              # Previous words\n    [1.0, 0.0],  # \"Kass\"\n    [0.5, 1.0],  # \"istus\"\n    [0.2, 0.3]   # \"toolil\"\n])\nvalues = keys  # Simplified\n\n# Calculate attention scores\nscores = torch.matmul(query, keys.T) / (keys.shape[1] ** 0.5)\nattention_weights = F.softmax(scores, dim=-1)\n\nprint(\"Attention weights:\")\nfor i, word in enumerate([\"Kass\", \"istus\", \"toolil\"]):\n    print(f\"{word}: {attention_weights[0][i]:.3f}\")\n\n# Apply attention\noutput = torch.matmul(attention_weights, values)\nprint(f\"\\nWeighted output: {output}\")",
        "explanation": "Attention mehhanism arvutab iga sõna olulisuse teiste sõnade suhtes. Kõrgem skoor tähendab tugevamat seost."
      }
    },
    {
      "id": "prefill-decode",
      "level": "roots",
      "title": "Eeltäide vs Dekodeerimine",
      "simpleName": "Lugemine ja kirjutamine",
      "explanation": "AI töötab kahes faasis. EELTÄIDE (Prefill): AI loeb kogu sinu küsimuse korraga läbi, väga kiiresti. DEKODEERIMINE (Decode): AI kirjutab vastust sõna-sõnalt, üks token korraga. Seepärast näed vastust ekraanil 'voolavalt' ilmumas - see on dekodeerimise faas töös.",
      "metaphor": "Lugemine vs Kirjutamine. Raamatut silmadega lugeda on kiire - sa haarad terve lõigu ühekorraga (prefill). Aga sama teksti käsitsi ümber kirjutada võtab palju kauem, sest pead iga tähe järjest kirjutama (decode).",
      "icon": "book-text",
      "complexity": 2,
      "prerequisites": ["tokens"]
    },
    {
      "id": "context-windows",
      "level": "roots",
      "title": "Konteksti Aknad (Context Windows)",
      "simpleName": "Töömälu",
      "explanation": "Konteksti aken määrab, kui palju teksti AI saab korraga meeles pidada ja töadelda. See on nagu AI 'töömälu' või 'lühiajaline mälu'. Näiteks GPT-4 suudab meeles pidada umbes 8000 tokenit (ca 6000 sõna). Kui vestlus muutub pikemaks, jääb algus 'akna' taha ja AI 'unustab' selle. Suurem konteksti aken = rohkem infot saab AI korraga kasutada, aga see on ka kallim ja aeglasem.",
      "metaphor": "Töömälu - nagu raamatu lugemine, kus mäletad korraga vaid viimast 5 lehekülge. Vanemad leheküljed unustatakse ära. Mõni inimene (või AI mudel) suudab meeles pidada rohkem lehekülgi korraga, aga see on kurnavam ja nõuab rohkem energiat.",
      "icon": "frame",
      "complexity": 1,
      "prerequisites": ["tokens"]
    },
    {
      "id": "hallucinations",
      "level": "roots",
      "title": "Hallutsinatsioonid",
      "simpleName": "Enesekindlad väljamõeldised",
      "explanation": "Hallutsinatsioonid tekivad siis, kui AI genereerib teavet, mis kõlab usutavalt, aga on vale või väljamõeldud. LLM-id on treenitud ennustama järgmist tokenit, mitte kontrollima faktide õigsust. Seega võib mudel 'leiutada' nimesid, kuupäevi, viiteid või fakte, eriti kui ta ei ole kindel. See on üks suurimaid väljakutseid LLM-ide kasutamisel kriitilistes rakendustes. RAG ja tõenduspõhine genereerimine aitavad seda vähendada.",
      "metaphor": "Enesekindlad väljamõeldised - nagu õpilane, kes arvab vastust enesekindlalt, kui ta tegelikult ei tea. Ta ei ütle 'Ma ei tea', vaid leiutab midagi, mis kõlab usutavalt. AI teeb seda sageli, sest ta on treenitud alati vastama, mitte tunnistama teadmatust.",
      "icon": "ghost",
      "complexity": 1,
      "prerequisites": ["tokens"]
    },
    {
      "id": "temperature-sampling",
      "level": "trunk",
      "title": "Temperatuur ja Valideerimine (Temperature & Sampling)",
      "simpleName": "Loovuse nupp",
      "explanation": "Temperatuur on parameeter, mis kontrollib AI väljundi juhuslikust ja loomingulisust. Madal temperatuur (näiteks 0.1) teeb mudeli väga ennustatavaks - ta valib alati kõige tõenäolisema tokeni. Kõrge temperatuur (näiteks 1.5) suurendab juhuslikust ja võimaldab vähem tõenäolisi valikuid. Madal temperatuur sobib faktiliste ülesannete jaoks (matemaatika, kood). Kõrge temperatuur sobib loovate ülesannete jaoks (jutustamine, brainstorming). Samuti on erinevaid valimismeetodeid (top-k, top-p/nucleus), mis mõjutavad, kuidas AI valib tokeneide vahel.",
      "metaphor": "Loovuse nupp - madal temperatuur on kalkulaator (ennustatav, täpne), kõrge temperatuur on kunstnik (loov, aga ettearvamatum). Kui küsid '2+2=?', tahad kalkulaatorit. Kui küsid 'Kirjuta muinasjutt', tahad kunstnikku.",
      "icon": "thermometer",
      "complexity": 1,
      "prerequisites": ["tokens"]
    },
    {
      "id": "prompting-basics",
      "level": "trunk",
      "title": "Promptimise Alused (Prompting Basics)",
      "simpleName": "Heade küsimuste esitamine",
      "explanation": "Prompting on AI-ga suhtlemise kunst. Hea prompt on selge, spetsiifiline ja annab konteksti. Halva prompti näide: 'Räägi mulle toidust'. Hea prompti näide: 'Soovita 3 kiiret taimetoiduretsepti, mis võtavad alla 30 minuti ja sisaldavad vähemalt 20g valku.' Põhiprintsiibid: 1) Ole spetsiifiline (täpne eesmärk), 2) Anna konteksti (taust, piirangud), 3) Määra formaat (loetelu, tabel, JSON), 4) Kasuta näiteid (few-shot learning), 5) Jaga keeruline ülesanne väiksemateks osadeks (chain-of-thought).",
      "metaphor": "Heade küsimuste esitamine - vahe 'Mis õhtuks söök?' ja 'Soovita 3 kiiret taimetoiduretsepti alla 30 minuti' on tohutu. Esimene küsimus annab liiga palju võimalusi ja ebaselge vastuse. Teine küsimus on täpne ja saad kasuliku vastuse.",
      "icon": "message-square",
      "complexity": 1,
      "prerequisites": ["tokens"]
    },
    {
      "id": "function-calling",
      "level": "branches",
      "title": "Funktsioonide Kutsumine (Function Calling)",
      "simpleName": "AI-le käte andmine",
      "explanation": "Function calling võimaldab LLM-idel kutsuda väliseid funktsioone ja tööriistu. Mudel ei täida funktsiooni ise, vaid genereerib struktureeritud kutse (JSON), mille rakendus täidab. Näiteks mudel võib otsustada, et ta vajab ilmaandmeid, genereerida kutse get_weather('Tallinn'), ja rakendus täidab selle ning tagastab tulemuse. Seejärel mudel kasutab seda infot vastuse genereerimiseks. See on võtmetähtsusega AI agentide jaoks - võimaldab neil kasutada andmebaase, API-sid, otsingumootoreid jne.",
      "metaphor": "AI-le käte andmine - lastes tal kasutada tööriistu nagu veebiotsing, kalendrite kontrollimine või e-mailide saatmine. AI on nagu intern, kes ei tea kõike, aga saab helistada ekspertidele (funktsioonidele) ja saada vastuseid.",
      "icon": "plug-2",
      "complexity": 2,
      "prerequisites": ["ai-agents"],
      "codeExample": {
        "language": "python",
        "code": "from openai import OpenAI\nimport json\n\nclient = OpenAI()\n\n# Define available functions\ntools = [{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"get_weather\",\n        \"description\": \"Hangi ilmateade linna jaoks\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"city\": {\"type\": \"string\", \"description\": \"Linna nimi\"}\n            },\n            \"required\": [\"city\"]\n        }\n    }\n}]\n\n# User asks about weather\nmessages = [{\"role\": \"user\", \"content\": \"Mis ilm on homme Tallinnas?\"}]\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=messages,\n    tools=tools\n)\n\n# Model decides to call function\nmessage = response.choices[0].message\nif message.tool_calls:\n    tool_call = message.tool_calls[0]\n    function_name = tool_call.function.name\n    function_args = json.loads(tool_call.function.arguments)\n    \n    # Execute function (simulated)\n    weather_result = {\"temperature\": \"8°C\", \"condition\": \"vihmane\"}\n    \n    # Send result back to model\n    messages.append(message)\n    messages.append({\n        \"role\": \"tool\",\n        \"content\": json.dumps(weather_result),\n        \"tool_call_id\": tool_call.id\n    })\n    \n    # Get final response\n    final_response = client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=messages\n    )\n    print(final_response.choices[0].message.content)",
        "explanation": "Function calling võimaldab AI-l 'otsustada', millal on vaja väliseid tööriistu kasutada. Mudel genereerib struktureeritud kutse, rakendus täidab selle, ja mudel kasutab tulemust lõpliku vastuse koostamiseks."
      }
    },
    {
      "id": "transformers",
      "level": "roots",
      "title": "Transformerid",
      "simpleName": "Meisterarhitektuur",
      "explanation": "Transformer on neuraalmõrgu arhitektuur, mis revolutsioneeris loomulike keelte töötlust 2017. aastal (paper 'Attention is All You Need'). Enne transformereid kasutati RNN-e ja LSTM-e, mis töötlesid teksti järjestikku (aeglane). Transformer töötleb kogu sisendi korraga paralleelselt, kasutades self-attention mehhanismi. See teeb mudeli palju kiiremaks ja võimaldab modelleerida pikemaid sõltuvusi. Kõik kaasaegsed LLM-id (GPT, BERT, Claude, Gemini) põhinevad transformer arhitektuuril. Põhikomponendid: multi-head attention, feed-forward võrgud, positsioonilised embeddingud, layer normalization.",
      "metaphor": "Meisterarhitektuur - plaan ChatGPT, BERT ja kõigi kaasaegsete AI keelemudelite taga. Nagu betoonkonstruktsioon ehituses - see on standard, mille peale kõik ehitatakse. Enne transformereid oli AI nagu kivist hoone (aeglane, piiratud). Transformerid on nagu terasbetooni leiutamine - äkki said võimalikuks pilvelõhkujad.",
      "icon": "cpu",
      "complexity": 2,
      "prerequisites": ["attention", "vectors"]
    },
    {
      "id": "training-vs-inference",
      "level": "roots",
      "title": "Treenimine vs Järeldamine (Training vs Inference)",
      "simpleName": "Kool vs Töö",
      "explanation": "Treenimine (training) on faas, kus mudel õpib miljonite tekstinäidete põhjal. See on väga kallis (miljonid dollarid), aeglane (nädalad või kuud) ja nõuab tuhandeid GPU-sid. Mudel kohandab oma sisemisi kaalusid, et ennustada järgmist tokenit võimalikult täpselt. Järeldamine (inference) on faas, kus valmis mudel vastab kasutaja küsimustele. See on suhteliselt kiire (sekundid) ja odav (sendid), sest mudeli kaalud on juba õpitud ja neid enam ei muudeta. Analoogia: treenimine on 4 aastat ülikoolis, järeldamine on töökoha tööl rakendamine.",
      "metaphor": "Kool vs Töö - treenimine on õppimine (kallis, aeglane, nõuab aastaid), järeldamine on õpitu rakendamine (kiire, odav, igapäevane töö). Kui mudel on kord treenitud, saab seda kasutada miljoneid kordi ilma uuesti õppimata.",
      "icon": "graduation-cap",
      "complexity": 1,
      "prerequisites": ["tokens"]
    }
  ]
}
